[
    {
        "type": "image",
        "img_path": "images/fa4c8f1e84ae0753880219e78bd92f53b6be3c1884dad0da129745936c465332.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "Introduction to Deep Learning ",
        "text_level": 1,
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "AlexanderAmini MIT Introduction to Deep Learning January 6,2025 ",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "\"Seeing\" the progress of deep learning throughout the years ",
        "text_level": 1,
        "page_idx": 1
    },
    {
        "type": "image",
        "img_path": "images/5b9a104bcbbe41dc786748043be5cc66fe092a2e2cb01d1b9b084cef09fa915e.jpg",
        "image_caption": [
            "2015 Goodfellow et al. "
        ],
        "image_footnote": [],
        "page_idx": 1
    },
    {
        "type": "image",
        "img_path": "images/738ee22888d0425788762d8b123ce3beeefe5d8c32d50a4c1949b0c2f3e1e035.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 1
    },
    {
        "type": "image",
        "img_path": "images/5e3c4aed8908b5c8a3e4059f4482ec2c4af3c52ee7aa8787e9196052df54f81a.jpg",
        "image_caption": [
            "2018 Karras,Laine,Aila. "
        ],
        "image_footnote": [],
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "2020 MIT Intro to Deep Learning ",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "Hieverybody,andwelcometo MIT6.S191 1.1Mviews 3months ago 88.2monthsago Thatiseasily thecleanest visualdeepfakelve ever seen.It must wOWwowwowiamamazed. havetakenages torender,because itjustlooksflawless. ",
        "page_idx": 3
    },
    {
        "type": "image",
        "img_path": "images/91d0bd54ace32f99f33791a568e6cdbb3915fe1d6410c133db83cd3642282f6d.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "2020 ",
        "text_level": 1,
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "...creating this 2 minute video required... ",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "2 hours of professional audio 50 hours of HD video Static,pre-defined script Over \\$15K USD of compute ",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "2020   \n...creating this2 minute video requred..   \n2 hours of professional audio   \n50 hours of HD video   \nStatic,pre-defined script   \nOver \\$I5K USD of compute ",
        "page_idx": 5
    },
    {
        "type": "image",
        "img_path": "images/d0b534376e5b6cbb076d9b20c313ff1186ce74752235eda9b50e6d52b7a912a3.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "What is Deep Learning? ",
        "text_level": 1,
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "ARTIFICIALINTELLIGENCE",
        "text_level": 1,
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "Any technique that enables computerstomimic human behavior ",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "MACHINE LEARNING ",
        "text_level": 1,
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "Abilityto learnwithout explicitly being programmed ",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "DEEP LEARNING ",
        "text_level": 1,
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "Extract patterns from data using neural networks ",
        "page_idx": 6
    },
    {
        "type": "image",
        "img_path": "images/0b18ccf1960b8c558a1bcf9e6679baff558077d908f52d6e8d3f45e59f6e0abd.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 6
    },
    {
        "type": "image",
        "img_path": "images/0244d2a52ca8fff9f6d6e67c3268493a114e21d28fca4298b2c448edd8998b3f.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "313472   \n174235 ",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "Teaching computers how to learn a task directly from raw data ",
        "text_level": 1,
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "Lecture Schedule ",
        "text_level": 1,
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "Intro toDeepLearning ",
        "page_idx": 7
    },
    {
        "type": "image",
        "img_path": "images/9782a83ced7534439130bd4cd9c6b1b9efdd53184a6b463029e0b5eee6ce398b.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 7
    },
    {
        "type": "image",
        "img_path": "images/95d89903dc83385818a5fc4d1179f219c61b8ca8e599ed7ab1d2a73302a893aa.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "Deep Sequence Modeling ",
        "page_idx": 7
    },
    {
        "type": "image",
        "img_path": "images/820536dbef5737d66ec2216ae7aa60147d04caabedec3df95e500d4448cd47ca.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "Deep Learning in Python;Music Generation ",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "Lecture 1   \n/n.6,2025   \n[Slides][Video] coming soon/   \nLecture 2   \n/an.6,2025   \n[Slides][Video] coming soon ",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "Software Lab 1 [Code] ",
        "page_idx": 7
    },
    {
        "type": "image",
        "img_path": "images/e2d7af203282f3dd8c9571e08da901ab38723e84794da8592244568014638b29.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "Deep Computer Vision ",
        "page_idx": 7
    },
    {
        "type": "image",
        "img_path": "images/15bf036de1e1e1747e79c1bb64e4ed786f8429c0607bfce0613d1f30f281f6a3.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 7
    },
    {
        "type": "image",
        "img_path": "images/8cfaf30a52b59b2a39ed52fb3eb1aad5153952cc950b88b88f6d4251b87d29ed.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "Deep Generative Modeling ",
        "page_idx": 7
    },
    {
        "type": "image",
        "img_path": "images/df3c237e0418e2b6da9dd4f0c34c7745c44fa6c9c03a3127ac493ee0047f6d12.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "Facial Detection Systems ",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "Lecture 3 ",
        "text_level": 1,
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "jan.7,2025 [Slides][Video] coming soon! ",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "Lecture 4   \n/an. 7,2025   \n[Slides][Video] coming soon ",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "Software Lab 2 [Paper][Code] ",
        "page_idx": 7
    },
    {
        "type": "image",
        "img_path": "images/f3a1d2c736fa45cdbf3e53825cd6a235fb59ab801c456ce7d8e71cd1a0078375.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "DeepReinforcement Learning ",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "NewFrontiers ",
        "page_idx": 7
    },
    {
        "type": "image",
        "img_path": "images/5cab16458ca8c167e9923df3353cb1848889ffe994d21c62846bb1ba0835e00c.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 7
    },
    {
        "type": "image",
        "img_path": "images/61695bf2598302cea540861deec913774acdf3e40c4a4a0dd515d996af3008f8.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "Large Language Models ",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "Lecture 5   \nn.&,2025   \n[Slides][video] coming soon!   \nLecture 6   \nJan.&,2025   \n[Slides][Video] coming soon ",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "Software Lab 3 [Code] ",
        "page_idx": 7
    },
    {
        "type": "image",
        "img_path": "images/5572511be897f3831479714c107cd4cd6569d3f0478194915564334f5d169b0b.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "Large Language Models ",
        "page_idx": 7
    },
    {
        "type": "image",
        "img_path": "images/c36c41a4709d754255982a3eaf2902f3e1d74f98db6c944270a8295b8030a840.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "Large Language Models(Il) ",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "Lecture 7   \nJan.9,2025   \n[Info][Slldes][Video] coming soon!   \nLecture 8   \nJan.9,2025   \n[info][Slldes][Video]coming soon! ",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "Final Project ",
        "page_idx": 7
    },
    {
        "type": "image",
        "img_path": "images/f6cfbf28af411d64a678412d6559f359ba22a8e55d73cf2795efc24a56fca77c.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "Work on final projects ",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "Al in the Wild ",
        "page_idx": 7
    },
    {
        "type": "image",
        "img_path": "images/daae0cca90830b46c996e954144700a140f42fc7c4394a8286473e9ce6ea4bff.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "Al forBiology ",
        "page_idx": 7
    },
    {
        "type": "image",
        "img_path": "images/82df56be783caa644beacf6a9beac5392a6b15b97105cbd635fb204955e0df44.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "ProjectPresentations ",
        "page_idx": 7
    },
    {
        "type": "image",
        "img_path": "images/e4aa7342ec7f209ce170b926fee931fd644c8a82f2685ab713d68ee5df48aab4.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "Lecture 10   \n/an. 10,2025   \n[info][Slides]Video]coming soon!   \nLecture 9   \nn. 10,2025   \n[Info][Slides][Video] coming soont ",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "Pitch your ideas,awards, and celebration! ",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "Jan6-Janl0，2025 Lecture Breakdown Labs:Tensorflow&PyTorch Competitions Final Projects+Prizes! ",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "Updated Software Labs: TensorFlow and PyTorch ",
        "text_level": 1,
        "page_idx": 8
    },
    {
        "type": "image",
        "img_path": "images/2498feaf4cc341596d7eac7a97aef7c30902cde586d00175f4a57a78af4034b4.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 8
    },
    {
        "type": "image",
        "img_path": "images/4ecf088f0788923b63f355177d2dadfc1213ee3b31a5e8bfdc6d07f77a60968d.jpg",
        "image_caption": [
            "PyTorch "
        ],
        "image_footnote": [],
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "TensorFlow ",
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "Labs and Prizes ",
        "text_level": 1,
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "All due Thursday I/09 at II:59pm ET. Instructions: bit.ly/deeplearning-syllabus ",
        "page_idx": 9
    },
    {
        "type": "image",
        "img_path": "images/16a66a32f549a36ee2d6765342c5812af2c328b23544ac2a1aa55655572fcea8.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "Music Generation ",
        "text_level": 1,
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "Build a neural network that can learn the genre of Irish folk songs and use it to generate brand new songs! ",
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "Prize: ",
        "page_idx": 9
    },
    {
        "type": "image",
        "img_path": "images/2d8478a03b79b22ef586f0044e950cac0490f961e0193afb8360b11ff1d584a8.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "Labs and Prizes ",
        "text_level": 1,
        "page_idx": 10
    },
    {
        "type": "text",
        "text": "All due Thursday I/09at II:59pm ET.Instructions:bit.ly/deeplearning-syllabus ",
        "page_idx": 10
    },
    {
        "type": "image",
        "img_path": "images/a629ae7d0314cd7a5f7e996251b7ea1dfd10c5399e59a61d87da0506faccde6f.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 10
    },
    {
        "type": "text",
        "text": "Computer Vision ",
        "text_level": 1,
        "page_idx": 10
    },
    {
        "type": "text",
        "text": "Build a neural network that can detect and mitigate biases in computer vision facial recognition systems! ",
        "page_idx": 10
    },
    {
        "type": "text",
        "text": "Prize: ",
        "page_idx": 10
    },
    {
        "type": "image",
        "img_path": "images/367e5604434dece0e916731cef8ddc81e68305603484065cb86cc47797ee8aa2.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 10
    },
    {
        "type": "text",
        "text": "Labs and Prizes ",
        "text_level": 1,
        "page_idx": 11
    },
    {
        "type": "text",
        "text": "All due Thursday I/09 at II:59pm ET. Instructions: bit.ly/deeplearning-syllabus ",
        "page_idx": 11
    },
    {
        "type": "image",
        "img_path": "images/17850743aa933243dc8ff4fc3bcdc3f0da62c325a4153a98c075f90e72fad99b.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 11
    },
    {
        "type": "text",
        "text": "Large Language Models ",
        "text_level": 1,
        "page_idx": 11
    },
    {
        "type": "text",
        "text": "Finetune the Gemma large language model (LLM) in a mystery style and evaluate withanAl judge! ",
        "page_idx": 11
    },
    {
        "type": "text",
        "text": "Prize: ",
        "page_idx": 11
    },
    {
        "type": "image",
        "img_path": "images/4bcf6f042bba98a576baa136b42e6a0cbc3509a5ed969d34fc246e96eb893c97.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 11
    },
    {
        "type": "text",
        "text": "Project Pitch Competition ",
        "text_level": 1,
        "page_idx": 12
    },
    {
        "type": "text",
        "text": "FridayI/Io. Instructions:bit.ly/deeplearning-syllabus ",
        "page_idx": 12
    },
    {
        "type": "image",
        "img_path": "images/66d69be76d4a2a9dd1e414df2a85a85656c31312ab4cacc89f22e82e6f187798.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 12
    },
    {
        "type": "text",
        "text": "Project Pitch Competition ",
        "text_level": 1,
        "page_idx": 12
    },
    {
        "type": "text",
        "text": "Presenta novel deep learning research   \nidea orapplication (5 minutes,strict)   \nPresentationson Friday, JanI0   \nSubmit groups by WedI/08 II:59pm ET   \nSubmit slides byThuI/09II:59pmET   \nInstructions: bit.ly/deeplearning-syllabus ",
        "page_idx": 12
    },
    {
        "type": "text",
        "text": "Prizes: ",
        "text_level": 1,
        "page_idx": 12
    },
    {
        "type": "text",
        "text": "Gold: NVIDIA3070GPU ",
        "page_idx": 12
    },
    {
        "type": "text",
        "text": "Silver: Smartwatch ",
        "page_idx": 12
    },
    {
        "type": "text",
        "text": "Bronze: HDMonitor ",
        "page_idx": 12
    },
    {
        "type": "text",
        "text": "送",
        "page_idx": 12
    },
    {
        "type": "image",
        "img_path": "images/d4b3594ac9e1ba48396a5b43c97c985642c9a5a39bd1e57f34d4e3159a18b683.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 12
    },
    {
        "type": "image",
        "img_path": "images/ad946d81525778e5e2a763ad0ff7eae750e05813c2429faba746185d7609c465.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 12
    },
    {
        "type": "text",
        "text": "Program Support ",
        "text_level": 1,
        "page_idx": 13
    },
    {
        "type": "text",
        "text": "·All lectures willbe held in person in 32-123   \n·Software labs $^ +$ office hours in 32-123   \n· Piazza: piazza.com/mit/spring2025/6s19l ·Useful for discussing labs &asking questions   \n· Program Website: introtodeeplearning.com · Lecture schedule · Slides and lecture recordings ·Software labs   \n· Syllabus: bit.ly/6sl9l-syllabus   \n· Labs: github.com/MITDeepLearning/introtodeeplearning   \n· Email us: introtodeeplearning-staff@mit.edu ",
        "page_idx": 13
    },
    {
        "type": "text",
        "text": "，？",
        "page_idx": 13
    },
    {
        "type": "text",
        "text": "Program Staff ",
        "text_level": 1,
        "page_idx": 14
    },
    {
        "type": "image",
        "img_path": "images/103da07d349e74e67e989ec778eb25a90c73dcd5821082ad214814ad2e81e86c.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 14
    },
    {
        "type": "image",
        "img_path": "images/bab316a4cb6be74dd03f2115b18ab64a4d60c1eb9a764b759e27cf9581f9a1ce.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 14
    },
    {
        "type": "text",
        "text": "AlexanderAmini Lead Instructor ",
        "page_idx": 14
    },
    {
        "type": "text",
        "text": "AvaAmini Lead Instructor ",
        "page_idx": 14
    },
    {
        "type": "image",
        "img_path": "images/34f2e5874ab50b050307bb4d5dd8f31b7fc95f53cf873945d5960ed0c008f709.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 14
    },
    {
        "type": "image",
        "img_path": "images/9fbeb779c8084b35636da463fa93c749f651fc1f7227dd879fdbc0e077b8f8a7.jpg",
        "image_caption": [
            "Victory Yinka-Banjo LeadTA "
        ],
        "image_footnote": [],
        "page_idx": 14
    },
    {
        "type": "text",
        "text": "Daniela Rus Director of CSAIL ",
        "page_idx": 14
    },
    {
        "type": "text",
        "text": "Program TAs ",
        "text_level": 1,
        "page_idx": 14
    },
    {
        "type": "image",
        "img_path": "images/2d19c05793858f5f68ca0c9127a7aeb3883b7029035008290c80f99d897bc133.jpg",
        "image_caption": [
            "Maxi "
        ],
        "image_footnote": [],
        "page_idx": 14
    },
    {
        "type": "image",
        "img_path": "images/127035238f38f10b8ef5c13b941c4a0781e31c0feda14d7249cb834be1b2da6b.jpg",
        "image_caption": [
            "Alex "
        ],
        "image_footnote": [],
        "page_idx": 14
    },
    {
        "type": "image",
        "img_path": "images/54c73b1e60e4749d39d574442c8a295678ee32fa741f501b29781f27b4b12332.jpg",
        "image_caption": [
            "Sadhana "
        ],
        "image_footnote": [],
        "page_idx": 14
    },
    {
        "type": "image",
        "img_path": "images/039f181f27507371549fadfcdbe68df93c1cf66f5b0e48381dfc80e68e3c1900.jpg",
        "image_caption": [
            "David "
        ],
        "image_footnote": [],
        "page_idx": 14
    },
    {
        "type": "text",
        "text": "introtodeeplearning-staff@mit.edu ",
        "page_idx": 14
    },
    {
        "type": "text",
        "text": "Thanks to Sponsors! ",
        "text_level": 1,
        "page_idx": 15
    },
    {
        "type": "image",
        "img_path": "images/7cfe5ecb8cac9ffe8e6a5b7f6bad682ff8bc0418a324102bc35ee4ff9de5bdcf.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 15
    },
    {
        "type": "text",
        "text": "Why Deep Learning and Why Now? ",
        "text_level": 1,
        "page_idx": 16
    },
    {
        "type": "text",
        "text": "Why Deep Learning? ",
        "text_level": 1,
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "Hand engineered featuresare time consuming,britle,and not scalable in practice Can we learn the underlying features directly from data? ",
        "page_idx": 17
    },
    {
        "type": "image",
        "img_path": "images/9cbb8ca3aa014a1dd27ed42cfd93779e60c052c224311e6a38f99f270490e893.jpg",
        "image_caption": [
            "LowLevel Features ",
            "Lines& Edges "
        ],
        "image_footnote": [],
        "page_idx": 17
    },
    {
        "type": "image",
        "img_path": "images/7b2490d0f92d224fc17477ef11cea7ebf3bba4f3005e8d151b96637298e0df50.jpg",
        "image_caption": [
            "Mid Level Features ",
            "Eyes&Nose&Ears "
        ],
        "image_footnote": [],
        "page_idx": 17
    },
    {
        "type": "image",
        "img_path": "images/f9ebbe7a0b08f2de76d3ea1a69b8ca7c5b3973c63ff97dbd3c54e4f15c0c784b.jpg",
        "image_caption": [
            "High Level Features ",
            "Facial Structure "
        ],
        "image_footnote": [],
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "Why I yNow? ",
        "text_level": 1,
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "Neural Networks date back decades,so why the dominance? ",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "Stochastic Gradient Descent ",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "1958 ",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "Perceptron LeamableWeights ",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "Backpropagation Multi-Layer Perceptron ",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "Deep Convolutional NN Digit Recognition ",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "1. Big Data ",
        "text_level": 1,
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "·Larger Datasets ·Easier Collection & Storage ",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "IMGENET ",
        "page_idx": 18
    },
    {
        "type": "image",
        "img_path": "images/b7bb27bfb1370ef85213b83dc9a82000b92cc8d7b87c3baa713ae26917ba7634.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "2. Hardware ",
        "text_level": 1,
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "·Graphics Processing Units (GPUs) Massively Parallelizable ",
        "page_idx": 18
    },
    {
        "type": "image",
        "img_path": "images/e629e95bb1c56f79ecfaf046df147d92e32093640e79de517b52f93aa66c2c80.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "3. Software ",
        "text_level": 1,
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "Improved Techniques · NewModels . Toolboxes ",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "1K X",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "The Perceptron The structural building block of deep learning ",
        "text_level": 1,
        "page_idx": 19
    },
    {
        "type": "text",
        "text": "The Perceptron: Forward Propagation ",
        "text_level": 1,
        "page_idx": 20
    },
    {
        "type": "image",
        "img_path": "images/6bf4f35665dceed21c7d7e08b05ec095beb347d3dbbbabb8ae470f569a8f3786.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "The Perceptron: Forward Propagation ",
        "text_level": 1,
        "page_idx": 21
    },
    {
        "type": "image",
        "img_path": "images/150fd1788dd7eaea227bbcc6cb8f388663737a09904fc813487c708b489495ee.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "The Perceptron: Forward Propagation ",
        "text_level": 1,
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "1 Wo S A $\\widehat { y } \\ = \\ g \\ \\left( \\ w _ { 0 } + \\sum _ { i = 1 } ^ { m } x _ { i } \\ w _ { i } \\right)$ x1 W1   \nW2 £ y=g（wo+XTW）   \nx2 wm where: $\\pmb { X } = \\left[ \\begin{array} { c } { x _ { 1 } } \\\\ { \\vdots } \\\\ { x _ { m } } \\end{array} \\right] \\mathrm { \\overset { } { a n d } } \\pmb { W } = \\left[ \\begin{array} { c } { w _ { 1 } } \\\\ { \\vdots } \\\\ { w _ { m } } \\end{array} \\right]$ xm   \nInputs Weights Sum Non-Linearity Output ",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "The Perceptron: Forward Propagation ",
        "text_level": 1,
        "page_idx": 23
    },
    {
        "type": "image",
        "img_path": "images/7ef424bdcf7298065f78782c793b2b7025b120e45a76b42bac726de1f9a0b785.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 23
    },
    {
        "type": "text",
        "text": "Activation Functions $\\hat { y } = g \\left( \\mathbf { \\nabla } w _ { 0 } + \\mathbf { \\nabla } \\mathbf { X } ^ { T } \\mathbf { W } \\right)$ ",
        "page_idx": 23
    },
    {
        "type": "text",
        "text": "·Example:sigmoid function ",
        "page_idx": 23
    },
    {
        "type": "equation",
        "img_path": "images/565325ba6967320b7241424bbbcabc2ac2342bff6e2c088660e7b0be09fc0e6f.jpg",
        "text": "$$\ng \\left( z \\right) = \\sigma \\left( z \\right) = \\frac { 1 } { 1 + e ^ { - z } }\n$$",
        "text_format": "latex",
        "page_idx": 23
    },
    {
        "type": "image",
        "img_path": "images/ee3e9b80bbd396fb0924066991f8eab56c6ee13982230e81c52b0785a4e51eac.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 23
    },
    {
        "type": "text",
        "text": "Common Activation Functions ",
        "text_level": 1,
        "page_idx": 24
    },
    {
        "type": "text",
        "text": "Sigmoid Function ",
        "page_idx": 24
    },
    {
        "type": "text",
        "text": "Hyperbolic Tangent ",
        "page_idx": 24
    },
    {
        "type": "text",
        "text": "Rectified Linear Unit (ReLU) ",
        "page_idx": 24
    },
    {
        "type": "image",
        "img_path": "images/7895c25d0159b31c01ab5e1b3abc62239128263115a5ca4ac688c99bd7fb7acf.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 24
    },
    {
        "type": "image",
        "img_path": "images/4ee5907e8d2de0fe1ffafed4e0c90fdf4eb6854f4eeba7e5bc0f48d6cac97999.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 24
    },
    {
        "type": "image",
        "img_path": "images/925417c869719710bda92cbaa12c17e643dca18fbc8d94649ba3e5a3f810623b.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 24
    },
    {
        "type": "equation",
        "img_path": "images/e62f45d7b7ac5f4376be90a12a7d04b440c77eabcf835a8e7b194344ee79bcc3.jpg",
        "text": "$$\ng \\left( z \\right) = \\frac { 1 } { 1 + e ^ { - z } }\n$$",
        "text_format": "latex",
        "page_idx": 24
    },
    {
        "type": "equation",
        "img_path": "images/d871719820168fb1625ff14fed659912c20f1c9a9d37c31357a3b375e43391a4.jpg",
        "text": "$$\ng ^ { \\prime } ( z ) = g ( z ) ( 1 - g ( z ) )\n$$",
        "text_format": "latex",
        "page_idx": 24
    },
    {
        "type": "image",
        "img_path": "images/6e4a657ea09c9538b63b6a44535fe620695952fce6a08bf25c589f86bf3fff76.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 24
    },
    {
        "type": "image",
        "img_path": "images/78dc820f26095fa2ad878a7e951c2cb57f447ca140bb10372296ed49da54b551.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 24
    },
    {
        "type": "image",
        "img_path": "images/a963abc77943a6270bb0ef7b9e09cb537552df94da3464c5ac07416cf87efb0f.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 24
    },
    {
        "type": "text",
        "text": "1F tf.math.tanh(z) torch.tanh(z) ",
        "page_idx": 24
    },
    {
        "type": "text",
        "text": "1F tf.nn.relu(z) torch.nn.ReLU(z) ",
        "page_idx": 24
    },
    {
        "type": "text",
        "text": "Importance of Activation Functions ",
        "text_level": 1,
        "page_idx": 25
    },
    {
        "type": "text",
        "text": "Thepurpose ofactivation functions is to introduce non-linearities into the network ",
        "page_idx": 25
    },
    {
        "type": "image",
        "img_path": "images/9903220c2252a3f214046e157e6232bcb8f6bbcdd6826a12462b7f481732915d.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 25
    },
    {
        "type": "text",
        "text": "What if we wanted to build a neural network to distinguish green vs red points? ",
        "page_idx": 25
    },
    {
        "type": "text",
        "text": "Importance of Activation Functions ",
        "text_level": 1,
        "page_idx": 26
    },
    {
        "type": "text",
        "text": "hepurposeofactivation functions is to introducenon-linearities into the network ",
        "page_idx": 26
    },
    {
        "type": "image",
        "img_path": "images/d937d79250b7e780d143a7ad4a4cce66d43baa4db55103582ae3b8b531bae868.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 26
    },
    {
        "type": "text",
        "text": "Linearactivation functions produce linear decisions no matter the network size ",
        "page_idx": 26
    },
    {
        "type": "text",
        "text": "Importance of Activation Functions ",
        "text_level": 1,
        "page_idx": 27
    },
    {
        "type": "text",
        "text": "hepurposeofactivation functions is to introduce non-linearitiesinto thenetwork ",
        "page_idx": 27
    },
    {
        "type": "image",
        "img_path": "images/acc777c73a1696b959444bfd510726fa1fff5b41c68ba7ba7921ba3549d58c6b.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 27
    },
    {
        "type": "image",
        "img_path": "images/bf3e0e07a5ef3e3248c8d8ae19c396cf2e391be464eb0a0e0b5939f1539523e7.jpg",
        "image_caption": [
            "Non-linearitiesallowustoapproximate arbitrarily complexfunctions "
        ],
        "image_footnote": [],
        "page_idx": 27
    },
    {
        "type": "text",
        "text": "Linearactivation functions produce linear decisions no matter the network size ",
        "page_idx": 27
    },
    {
        "type": "text",
        "text": "The Perceptron: Example ",
        "text_level": 1,
        "page_idx": 28
    },
    {
        "type": "image",
        "img_path": "images/8267183efeee22d8599c0d2caf19c4e1304adfcb9dca15df7c3f46980651f7aa.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 28
    },
    {
        "type": "text",
        "text": "We hae: $w _ { 0 } = 1$ $\\pmb { W } \\ = \\ \\bigl [ _ { - 2 } ^ { 3 } \\bigr ]$ ",
        "page_idx": 28
    },
    {
        "type": "equation",
        "img_path": "images/a0102daa7583a04eb7c4046bd241baae2c982dd00fa5caabbd07e840527b39ac.jpg",
        "text": "$$\n\\begin{array} { r l } & { \\hat { \\boldsymbol { y } } = \\boldsymbol { g } \\left( \\boldsymbol { w } _ { 0 } + \\boldsymbol { X } ^ { T } \\boldsymbol { W } \\mathrm { \\Sigma } \\right) } \\\\ & { \\mathrm { \\Sigma } = \\boldsymbol { g } \\left( 1 + \\left[ \\boldsymbol { x } _ { 1 } \\right] ^ { T } \\left[ \\begin{array} { c } { 3 } \\\\ { - 2 } \\end{array} \\right] \\right) } \\\\ & { \\hat { \\boldsymbol { y } } = \\boldsymbol { g } \\left( 1 + 3 \\boldsymbol { x } _ { 1 } - 2 \\boldsymbol { x } _ { 2 } \\right) } \\end{array}\n$$",
        "text_format": "latex",
        "page_idx": 28
    },
    {
        "type": "text",
        "text": "This is just a line in 2D！ ",
        "page_idx": 28
    },
    {
        "type": "text",
        "text": "The Perceptron: Example ",
        "text_level": 1,
        "page_idx": 29
    },
    {
        "type": "text",
        "text": "$\\hat { y } = g ( 1 + 3 x _ { 1 } - 2 x _ { 2 } )$ S1 x2 $\\sum \\limits _ { i = 1 } ^ { \\infty } i = 1$ 0 0= -2x2 3 x1 1+3x1 -2 x1 x2 ",
        "page_idx": 29
    },
    {
        "type": "text",
        "text": "The Perceptron: Example ",
        "text_level": 1,
        "page_idx": 30
    },
    {
        "type": "image",
        "img_path": "images/23d6be4b48f6c24eca46ac317e815404655ca0f3605059509c8cf2cf12012144.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 30
    },
    {
        "type": "text",
        "text": "The Perceptron: Example ",
        "text_level": 1,
        "page_idx": 31
    },
    {
        "type": "image",
        "img_path": "images/5469b1df394acf54889949027146ced98e05aadf7ab5543be7d65f91b4f3a57b.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 31
    },
    {
        "type": "text",
        "text": "Building Neural Networks with Perceptrons ",
        "text_level": 1,
        "page_idx": 32
    },
    {
        "type": "text",
        "text": "The Perceptron: Simplified ",
        "text_level": 1,
        "page_idx": 33
    },
    {
        "type": "equation",
        "img_path": "images/620b054bc85c7191c28993f6e198a415644d8d817eebff0aa520859f5776047f.jpg",
        "text": "$$\n\\hat { y } = g \\left( \\mathbf { \\nabla } w _ { 0 } + \\mathbf { \\nabla } \\mathbf { X } ^ { T } \\mathbf { W } \\right)\n$$",
        "text_format": "latex",
        "page_idx": 33
    },
    {
        "type": "image",
        "img_path": "images/1b3019c3a5612a1bb534c44baee6a1bb9efa403d807c934fb8f1af9a095e7a8b.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 33
    },
    {
        "type": "text",
        "text": "The Perceptron: Simplified ",
        "text_level": 1,
        "page_idx": 34
    },
    {
        "type": "image",
        "img_path": "images/7dab6271316ce1250f3e022729456b8c428f67e2c8d5f10387b5478892ad4a75.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 34
    },
    {
        "type": "text",
        "text": "Multi Output Perceptron ",
        "text_level": 1,
        "page_idx": 35
    },
    {
        "type": "text",
        "text": "Becauseallinputs are densely connected toalloutputs,these layers are called Dense layers ",
        "page_idx": 35
    },
    {
        "type": "image",
        "img_path": "images/5be4c1adb0273257305c7ddb143cc425b531a0d98f5ae63d5dbe557540783faa.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 35
    },
    {
        "type": "text",
        "text": "Dense layer fromscratch ",
        "text_level": 1,
        "page_idx": 36
    },
    {
        "type": "text",
        "text": "1F ",
        "text_level": 1,
        "page_idx": 36
    },
    {
        "type": "text",
        "text": "class MyDenseLayer(tf.keras.layers.Layer): def_init_(self,input_dim,output_dim) super(MyDenseLayer,self)._init__() ",
        "page_idx": 36
    },
    {
        "type": "text",
        "text": "self.w self.add_weight([input_dim,output_dim]) self.b self.add_weight([l,output_dim]) ",
        "page_idx": 36
    },
    {
        "type": "text",
        "text": "def call(self,inputs): ",
        "page_idx": 36
    },
    {
        "type": "text",
        "text": "-tf.matmul(inputs,self.w) self.b output tf.math.sigmoid(z) return output ",
        "page_idx": 36
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 36
    },
    {
        "type": "text",
        "text": "class MyDenseLayer(nn.Module): def init(self, input_dim,output_dim)： super(MyDenseLayer, self)._init_() ",
        "page_idx": 36
    },
    {
        "type": "text",
        "text": "Initialize weights and bias   \nself.W=nn.Parameter(torch.randn(input_dim, output_dim,requires_grad=True)   \nself.b=nn.Parameter(torch.randn(l,output_dim, requires_grad=True) ",
        "page_idx": 36
    },
    {
        "type": "text",
        "text": "def forward(self,inputs): ",
        "text_level": 1,
        "page_idx": 36
    },
    {
        "type": "text",
        "text": "#Forward propagate the inputs Z torch.matmul(inputs,self.W)+self.b ",
        "page_idx": 36
    },
    {
        "type": "text",
        "text": "Feed through a non-linear activation output torch.sigmoid(z) return output ",
        "page_idx": 36
    },
    {
        "type": "text",
        "text": "Multi Output Perceptron ",
        "text_level": 1,
        "page_idx": 37
    },
    {
        "type": "text",
        "text": "Because allinputsare densely connected toall outputs,these layers are called Dense layers ",
        "page_idx": 37
    },
    {
        "type": "image",
        "img_path": "images/b25627a02c98dbf8df989721f00c76be5314b0d6c9d3629f6a2a1b95ecd62d39.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 37
    },
    {
        "type": "text",
        "text": "Single Layer Neural Network ",
        "text_level": 1,
        "page_idx": 38
    },
    {
        "type": "image",
        "img_path": "images/d57473dbf05e3ec8d4c11c969b8ee63e25f64ab445ade96c54d860daa7894514.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 38
    },
    {
        "type": "text",
        "text": "Single Layer Neural Network ",
        "text_level": 1,
        "page_idx": 39
    },
    {
        "type": "image",
        "img_path": "images/d1bb6d228917cca121042cb7e8bcf26d4693c275d9a279f04cc3889edd7eb8a1.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 39
    },
    {
        "type": "text",
        "text": "Multi Output Perceptron ",
        "text_level": 1,
        "page_idx": 40
    },
    {
        "type": "text",
        "text": "import tensorflowastf   \nmodel-tf.keras.Sequential([ S191 tf.keras.layers.Dense(n), tf.keras.layers.Dense(2)   \n1） 公1   \nfrom torch import nn x1   \nmodel nn.Sequential( Z2 nn.Linear(m,n), nn.ReLU(), x2 nn.Linear(n,2） Z3 2 M Zn Inputs Hidden Output ",
        "page_idx": 40
    },
    {
        "type": "text",
        "text": "Deep Neural Network ",
        "text_level": 1,
        "page_idx": 41
    },
    {
        "type": "text",
        "text": "Zk,1 1   \nx1 ZK,2 y   \nx2 ZK,3   \nMIT ZK,nk Hidden Output $z _ { k , i } = w _ { 0 , i } ^ { ( k ) } + et { } { ^ { n _ { k - 1 } } } \\sum _ { j = 1 } ^ { n _ { k - 1 } } g ( z _ { k - 1 , j } ) w _ { j , i } ^ { ( k ) }$ ",
        "page_idx": 41
    },
    {
        "type": "text",
        "text": "Deep Neural Network ",
        "text_level": 1,
        "page_idx": 42
    },
    {
        "type": "image",
        "img_path": "images/528508b48fdb12fe78f0fd78a001a8195b5b24e4aec0a9ee94e1e9fe1c9ba8dc.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 42
    },
    {
        "type": "text",
        "text": "import tensorflow astf model=tf.keras.Sequential([ tf.keras.layers.Dense(n), tf.keras.layers.Dense(n2), tf.keras.layers.Dense(2) ",
        "page_idx": 42
    },
    {
        "type": "text",
        "text": "from torch import nn   \nmodel = nn.Sequential( nn.Linear(m,n1)， nn.ReLU(), nn.ReLU(), nn.Linear(nK,2) ",
        "page_idx": 42
    },
    {
        "type": "text",
        "text": "Applying Neural Networks ",
        "text_level": 1,
        "page_idx": 43
    },
    {
        "type": "text",
        "text": "Example Problem ",
        "text_level": 1,
        "page_idx": 44
    },
    {
        "type": "text",
        "text": "Will pass this class? ",
        "page_idx": 44
    },
    {
        "type": "text",
        "text": "Let's start with a simple two feature model $x _ { 1 } =$ Number of lectures you attend X2= Hours spent on the final project ",
        "page_idx": 44
    },
    {
        "type": "text",
        "text": "Example Problem:Will I pass this class? ",
        "text_level": 1,
        "page_idx": 45
    },
    {
        "type": "text",
        "text": "$\\scriptstyle x _ { 2 } =$ Hours :.19   \nspent on the   \nfinal project Legend Pass Fail   \nM. $x _ { 1 } =$ Number of lectures you attend ",
        "page_idx": 45
    },
    {
        "type": "text",
        "text": "Example Problem:Will I pass this class? ",
        "text_level": 1,
        "page_idx": 46
    },
    {
        "type": "text",
        "text": "$\\scriptstyle x _ { 2 } =$ Hours ·.19   \nspent on the   \nfinal project Legend Pass [] Fail   \nM. $x _ { 1 } =$ Number of lectures you attend ",
        "page_idx": 46
    },
    {
        "type": "text",
        "text": "Example Problem: Will  pass this class? ",
        "text_level": 1,
        "page_idx": 47
    },
    {
        "type": "image",
        "img_path": "images/3b1690621180b5b7761c0c2b93252be19bb5d1f95c9c6de9fdbec515496d5e4d.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 47
    },
    {
        "type": "text",
        "text": "Predicted: 0.1 ",
        "page_idx": 47
    },
    {
        "type": "text",
        "text": "Example Problem: Will  pass this class? ",
        "text_level": 1,
        "page_idx": 48
    },
    {
        "type": "image",
        "img_path": "images/5fae7c0c010e7abcffe92ec5049b13ed6ac2fc5d232916d88cd5357c36fe90a4.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 48
    },
    {
        "type": "text",
        "text": "Quantifying Loss ",
        "text_level": 1,
        "page_idx": 49
    },
    {
        "type": "text",
        "text": "Theloss of our networkmeasures the cost incurred from incorrect predictions ",
        "page_idx": 49
    },
    {
        "type": "text",
        "text": "Z1 x1 x(1)=[4,5] Predicted:0.1 Z2 y Actual: 1 x2 MI L(f(xi;W),y(𝑖)) Z3 Predicted Actual ",
        "page_idx": 49
    },
    {
        "type": "text",
        "text": "Empirical Loss ",
        "text_level": 1,
        "page_idx": 50
    },
    {
        "type": "text",
        "text": "Theempirical lossmeasures the total loss over our entire dataset ",
        "page_idx": 50
    },
    {
        "type": "image",
        "img_path": "images/f0a5a7a36da40f4921076dce719ce50e3a18a99f712d64520cc5660f460939eb.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 50
    },
    {
        "type": "text",
        "text": "Also known as: ",
        "page_idx": 50
    },
    {
        "type": "text",
        "text": "Objective function . Cost function Empirical Risk ",
        "page_idx": 50
    },
    {
        "type": "image",
        "img_path": "images/642ca63b55ee7f70809474c9c946961dbe0272959d344e64d8532394bb643af0.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 50
    },
    {
        "type": "equation",
        "img_path": "images/9b02015bb20a64750cd8113a1a7e8097f6573e508c3114135fe1b9676d7d149c.jpg",
        "text": "$$\n\\boldsymbol { J } ( \\boldsymbol { W } ) = \\frac { 1 } { n } { \\sum } _ { i = 1 } ^ { n } \\mathcal { L } \\big ( \\underline { { f \\big ( \\boldsymbol { x } ^ { ( i ) } ; \\boldsymbol { W } \\big ) } } , \\underline { { y ^ { ( i ) } } } \\big )\n$$",
        "text_format": "latex",
        "page_idx": 50
    },
    {
        "type": "text",
        "text": "Binary Cross Entropy Loss ",
        "text_level": 1,
        "page_idx": 51
    },
    {
        "type": "text",
        "text": "Cross entropy losscan be used with models that output a probability between O and l ",
        "page_idx": 51
    },
    {
        "type": "text",
        "text": "f(x) y 5225 x1 Z1 [0.1] ××v 一 X= x2 Z2 y 0.8 0.6 1… 0 ： Z3 10 7 n y@1og(f(x⑥;w)）+(1-y@)log(1-f(x①;)） n Actual Predicted Actual Predicted ",
        "page_idx": 51
    },
    {
        "type": "text",
        "text": "Mean Squared Error Loss ",
        "text_level": 1,
        "page_idx": 52
    },
    {
        "type": "text",
        "text": "Mean squared error losscan be used with regression models that output continuous real numbers ",
        "page_idx": 52
    },
    {
        "type": "text",
        "text": "f(x) y 5225 x1 ZI 308 X= Z2 85 x2 ： ： MI $J ( W ) = \\frac { 1 } { n } { \\sum } _ { i = 1 } ^ { n } \\underbrace { \\Big ( y ^ { ( i ) } - f \\big ( x ^ { ( i ) } ; W \\big ) \\Big ) ^ { 2 } } _ { }$ Z3 Final Grades (percentage) ActualPredicted ",
        "page_idx": 52
    },
    {
        "type": "text",
        "text": "Training Neural Networks ",
        "text_level": 1,
        "page_idx": 53
    },
    {
        "type": "text",
        "text": "Loss Optimization ",
        "text_level": 1,
        "page_idx": 54
    },
    {
        "type": "text",
        "text": "We want to find the network weights that achieve the lowest loss ",
        "page_idx": 54
    },
    {
        "type": "equation",
        "img_path": "images/8a5dfe7633b6ac70eabcbaef357cc177dbe12af46746b0726c766f665e09a786.jpg",
        "text": "$$\nW ^ { * } = \\underset { W } { \\mathrm { a r g m i n } } \\frac { 1 } { n } { \\sum _ { i = 1 } ^ { n } } \\mathcal { L } \\big ( f \\big ( x ^ { ( i ) } ; W \\big ) , y ^ { ( i ) } \\big )\n$$",
        "text_format": "latex",
        "page_idx": 54
    },
    {
        "type": "equation",
        "img_path": "images/403a2531f9fe1f3a7ea13c19781ba34f818b068002134ef5cad6dc4c38a095ce.jpg",
        "text": "$$\nW ^ { * } = \\underset { W } { \\mathrm { a r g m i n } } J ( W )\n$$",
        "text_format": "latex",
        "page_idx": 54
    },
    {
        "type": "text",
        "text": "Loss Optimization ",
        "text_level": 1,
        "page_idx": 55
    },
    {
        "type": "text",
        "text": "We want to find the network weights that achieve the lowest loss ",
        "page_idx": 55
    },
    {
        "type": "equation",
        "img_path": "images/dda7f0fe779fd71c90358767c639693f313de7255ac46c1c14d0230803537e05.jpg",
        "text": "$$\nW ^ { * } = \\underset { W } { \\mathrm { a r g m i n } } \\frac { 1 } { n } { \\sum _ { i = 1 } ^ { n } } \\mathcal { L } \\big ( f \\big ( x ^ { ( i ) } ; W \\big ) , y ^ { ( i ) } \\big )\n$$",
        "text_format": "latex",
        "page_idx": 55
    },
    {
        "type": "equation",
        "img_path": "images/2b1a7680341409f1525117fe5670705b54e0bdd1040e2629280000deed9d3b96.jpg",
        "text": "$$\nW ^ { * } = \\underset { W } { \\mathrm { a r g m i n } } J ( W )\n$$",
        "text_format": "latex",
        "page_idx": 55
    },
    {
        "type": "equation",
        "img_path": "images/85aa94434c73582ad7e94d68320210ca7a38a3272af9754f055f9bbf8f9688be.jpg",
        "text": "$$\n{ \\pmb W } = \\left\\{ { \\pmb W } ^ { ( 0 ) } , { \\pmb W } ^ { ( 1 ) } , \\cdots \\right\\}\n$$",
        "text_format": "latex",
        "page_idx": 55
    },
    {
        "type": "text",
        "text": "Loss Optimization ",
        "text_level": 1,
        "page_idx": 56
    },
    {
        "type": "equation",
        "img_path": "images/b85c848bd93354c04d7e68a0c602176cc92a63048c47ad5bf2832bb270114a5f.jpg",
        "text": "$$\nW ^ { * } = \\underset { W } { \\mathrm { a r g m i n } } J ( W )\n$$",
        "text_format": "latex",
        "page_idx": 56
    },
    {
        "type": "text",
        "text": "Remember: Our loss isa function of the network weights! ",
        "page_idx": 56
    },
    {
        "type": "image",
        "img_path": "images/2b5204c597ce3c5ec93a45c38b8d5e5914966cbbd182ec8c7b15144e2fc116b4.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 56
    },
    {
        "type": "text",
        "text": "J(Wo, W1) ",
        "page_idx": 56
    },
    {
        "type": "text",
        "text": "Loss Optimization ",
        "text_level": 1,
        "page_idx": 57
    },
    {
        "type": "text",
        "text": "Randomly pick an initial $( w _ { 0 } , w _ { 1 } )$ ",
        "page_idx": 57
    },
    {
        "type": "image",
        "img_path": "images/9961fe1fe06942e4a65b84e52e78653bb47b421682c730b4bef5e0b5acdad84f.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 57
    },
    {
        "type": "text",
        "text": "J(Wo, W1) ",
        "page_idx": 57
    },
    {
        "type": "text",
        "text": "Loss Optimization ",
        "text_level": 1,
        "page_idx": 58
    },
    {
        "type": "text",
        "text": "Compute gradient,J(W) ",
        "page_idx": 58
    },
    {
        "type": "image",
        "img_path": "images/a6fe8808f8259032480bd7b22682076319312ac7a206bac261925c7ccd6f2a88.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 58
    },
    {
        "type": "text",
        "text": "J(Wo, W1) ",
        "page_idx": 58
    },
    {
        "type": "text",
        "text": "Loss Optimization ",
        "text_level": 1,
        "page_idx": 59
    },
    {
        "type": "text",
        "text": "Take small step in opposite direction of gradient ",
        "page_idx": 59
    },
    {
        "type": "image",
        "img_path": "images/28ae492dec0d2c30aac0743d9f82ee015e8ab14a9807a85555d72a216814ddd7.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 59
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 59
    },
    {
        "type": "text",
        "text": "Gradient Descent ",
        "text_level": 1,
        "page_idx": 60
    },
    {
        "type": "text",
        "text": "Repeat until convergence ",
        "page_idx": 60
    },
    {
        "type": "image",
        "img_path": "images/36c26b323615b006cc0b6a484914f886745328bd268a08fd4dadbdc7ac9630b3.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 60
    },
    {
        "type": "text",
        "text": "J(Wo,W1) ",
        "page_idx": 60
    },
    {
        "type": "text",
        "text": "Gradient Descent ",
        "text_level": 1,
        "page_idx": 61
    },
    {
        "type": "text",
        "text": "Algorithm ",
        "text_level": 1,
        "page_idx": 61
    },
    {
        "type": "text",
        "text": "I.Initialize weights randomly ${ \\sim } \\mathcal { N } ( 0 , \\sigma ^ { 2 } )$   \n2.Loop until convergence:   \n3. Compute gradient, $\\textstyle { \\frac { \\partial J ( W ) } { \\partial W } }$   \n4. Update weights, $\\pmb { W } \\gets \\pmb { W } - \\eta \\frac { \\partial J ( \\pmb { W } ) } { \\partial \\pmb { W } }$   \n5.Retum weights ",
        "page_idx": 61
    },
    {
        "type": "text",
        "text": "Gradient Descent ",
        "text_level": 1,
        "page_idx": 62
    },
    {
        "type": "text",
        "text": "Algorithm ",
        "text_level": 1,
        "page_idx": 62
    },
    {
        "type": "text",
        "text": "1. Initialize weights randomly ${ \\sim } \\mathcal { N } ( 0 , \\sigma ^ { 2 } )$   \n2.Loop until convergence:   \n3. Compute gradient, $\\textstyle { \\frac { \\partial J ( W ) } { \\partial W } }$   \n4. Update weights, $\\pmb { W } \\gets \\pmb { W } - \\eta \\frac { \\partial J ( \\pmb { W } ) } { \\partial W }$   \n5.Return weights ",
        "page_idx": 62
    },
    {
        "type": "text",
        "text": "import tensorflow as tf weights=tf.Variable([tf.random.normal()]) ",
        "page_idx": 62
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 62
    },
    {
        "type": "text",
        "text": "while True: #loop forever withtf.GradientTape()asg： loss=compute_loss(weights) gradient=g.gradient(loss,weights) ",
        "page_idx": 62
    },
    {
        "type": "text",
        "text": "weights=weights-lr\\*gradient ",
        "page_idx": 62
    },
    {
        "type": "text",
        "text": "Gradient Descent ",
        "text_level": 1,
        "page_idx": 63
    },
    {
        "type": "text",
        "text": "Algorithm ",
        "text_level": 1,
        "page_idx": 63
    },
    {
        "type": "text",
        "text": "1. Initialize weights randomly ${ \\sim } \\mathcal { N } ( 0 , \\sigma ^ { 2 } )$   \n2.Loop until convergence:   \n3. Compute gradient, $\\textstyle { \\frac { \\partial J ( W ) } { \\partial W } }$   \n4. Update weights, $\\pmb { W } \\gets \\pmb { W } - \\eta \\frac { \\partial J ( \\pmb { W } ) } { \\partial W }$   \n5.Return weights ",
        "page_idx": 63
    },
    {
        "type": "text",
        "text": "import tensorflow as tf weights=tf.Variable([tf.random.normal()]) ",
        "page_idx": 63
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 63
    },
    {
        "type": "text",
        "text": "while True: #loop forever withtf.GradientTape() as g： loss= compute_loss(weights) gradient-ggradient(loss,weights) ",
        "page_idx": 63
    },
    {
        "type": "text",
        "text": "Computing Gradients: Backpropagation ",
        "text_level": 1,
        "page_idx": 64
    },
    {
        "type": "image",
        "img_path": "images/a0de3448dc9d4708c37a249351e037cc848c2b65168c11355448beb7c7934bfc.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 64
    },
    {
        "type": "text",
        "text": "How does a small change in one weight (ex. $w _ { 2 } ,$ afect thefinal lossJ(W) ",
        "page_idx": 64
    },
    {
        "type": "text",
        "text": "Computing Gradients: Backpropagation ",
        "text_level": 1,
        "page_idx": 65
    },
    {
        "type": "image",
        "img_path": "images/998979d7ad60634a8c5e7ceecf5f13af568c4dadbb8677b03c512d4d1dddd6ee.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 65
    },
    {
        "type": "text",
        "text": "Let's use the chain rule! ",
        "page_idx": 65
    },
    {
        "type": "text",
        "text": "Computing Gradients: Backpropagation ",
        "text_level": 1,
        "page_idx": 66
    },
    {
        "type": "image",
        "img_path": "images/a9db52b2b29817393923d3026d1456fe41c6ec48e190c7e9dd90bf36669836e5.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 66
    },
    {
        "type": "text",
        "text": "Computing Gradients: Backpropagation ",
        "text_level": 1,
        "page_idx": 67
    },
    {
        "type": "image",
        "img_path": "images/10d02420eb9b0856c465ac666a05836e9cd73a2b16f39503ccc75b2948ded74f.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 67
    },
    {
        "type": "text",
        "text": "Computing Gradients: Backpropagation ",
        "text_level": 1,
        "page_idx": 68
    },
    {
        "type": "image",
        "img_path": "images/2d8f32444901b03a0a1fa98916c80f674d52f523356901ecb9e82d9d78b05d53.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 68
    },
    {
        "type": "text",
        "text": "Computing Gradients: Backpropagation ",
        "text_level": 1,
        "page_idx": 69
    },
    {
        "type": "image",
        "img_path": "images/f1723323cc06a4672cfa2a136b8a1ebd382c80ba892122d77412b133f751efa0.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 69
    },
    {
        "type": "text",
        "text": "Repeatthis forevery weight inthenetworkusinggradients from later layers ",
        "page_idx": 69
    },
    {
        "type": "text",
        "text": "Neural Networks in Practice: Optimization ",
        "text_level": 1,
        "page_idx": 70
    },
    {
        "type": "text",
        "text": "Training Neural Networks is Dificult ",
        "text_level": 1,
        "page_idx": 71
    },
    {
        "type": "image",
        "img_path": "images/f5cf5677cb74fdd51489cc95d17c2d8e850ec1b71b3cb46259949db172ade11f.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 71
    },
    {
        "type": "text",
        "text": "Loss Functions Can Be Difficult to Optimize ",
        "text_level": 1,
        "page_idx": 72
    },
    {
        "type": "text",
        "text": "Remember: ",
        "text_level": 1,
        "page_idx": 72
    },
    {
        "type": "text",
        "text": "Optimization through gradient descent ",
        "page_idx": 72
    },
    {
        "type": "equation",
        "img_path": "images/0b161c5bb0f445e2849911ca2686bc988a687f85785a450183e06195e95d0b28.jpg",
        "text": "$$\n\\pmb { W }  \\pmb { W } - \\eta \\frac { \\partial J ( \\pmb { W } ) } { \\partial \\pmb { W } }\n$$",
        "text_format": "latex",
        "page_idx": 72
    },
    {
        "type": "text",
        "text": "Loss Functions Can Be Diffcult to Optimize ",
        "text_level": 1,
        "page_idx": 73
    },
    {
        "type": "text",
        "text": "Remember: ",
        "text_level": 1,
        "page_idx": 73
    },
    {
        "type": "text",
        "text": "Optimization through gradient descent ",
        "page_idx": 73
    },
    {
        "type": "text",
        "text": "How can we set the learning rate? ",
        "page_idx": 73
    },
    {
        "type": "text",
        "text": "Setting the Learning Rate ",
        "text_level": 1,
        "page_idx": 74
    },
    {
        "type": "text",
        "text": "Small learningrateconverges slowlyand gets stuck in false local minima ",
        "page_idx": 74
    },
    {
        "type": "text",
        "text": "250 200 MIT 6.S19 Initialguess 5 -2 -1 0 W ",
        "page_idx": 74
    },
    {
        "type": "text",
        "text": "Setting the Learning Rate ",
        "text_level": 1,
        "page_idx": 75
    },
    {
        "type": "text",
        "text": "Large learningrates overshoot,becomeunstableand diverge ",
        "page_idx": 75
    },
    {
        "type": "text",
        "text": "250200MIT 6.S19Initial guess3 -2 -1 0W",
        "page_idx": 75
    },
    {
        "type": "text",
        "text": "Setting the Learning Rate ",
        "text_level": 1,
        "page_idx": 76
    },
    {
        "type": "text",
        "text": "Stable learningrates converge smoothlyand avoid local minima ",
        "page_idx": 76
    },
    {
        "type": "text",
        "text": "250 200 MUT 6.S19 Initialguss 3 -2 -1 0 W ",
        "page_idx": 76
    },
    {
        "type": "text",
        "text": "How to deal with this? ",
        "text_level": 1,
        "page_idx": 77
    },
    {
        "type": "text",
        "text": "Idea 1：",
        "text_level": 1,
        "page_idx": 77
    },
    {
        "type": "text",
        "text": "Try lots of diferent learning rates and see what works\"just right\" ",
        "page_idx": 77
    },
    {
        "type": "text",
        "text": "How to deal with this? ",
        "text_level": 1,
        "page_idx": 78
    },
    {
        "type": "text",
        "text": "Idea 1：",
        "page_idx": 78
    },
    {
        "type": "text",
        "text": "Try lots of different learning rates and see what works\"just right\" ",
        "page_idx": 78
    },
    {
        "type": "text",
        "text": "Idea 2: ",
        "text_level": 1,
        "page_idx": 78
    },
    {
        "type": "text",
        "text": "Do something smarter! Design an adaptive learning rate that \"adapts\"to the landscape ",
        "page_idx": 78
    },
    {
        "type": "text",
        "text": "Adaptive Learning Rates ",
        "text_level": 1,
        "page_idx": 79
    },
    {
        "type": "text",
        "text": "·Learning rates are no longer fixed Can be made larger or smaller depending on: ·how large gradient is how fast learning is happening size of particular weights ■ etc.. ",
        "page_idx": 79
    },
    {
        "type": "text",
        "text": "Gradient Descent Algorithms ",
        "text_level": 1,
        "page_idx": 80
    },
    {
        "type": "text",
        "text": "Algorithm ",
        "text_level": 1,
        "page_idx": 80
    },
    {
        "type": "text",
        "text": "TF Implementation ",
        "page_idx": 80
    },
    {
        "type": "text",
        "text": "Torch Implementation ",
        "page_idx": 80
    },
    {
        "type": "text",
        "text": "Reference ",
        "text_level": 1,
        "page_idx": 80
    },
    {
        "type": "text",
        "text": "Kiefer&Wolfowitz,1952. ",
        "page_idx": 80
    },
    {
        "type": "text",
        "text": "Kingma et al.,2014. ",
        "page_idx": 80
    },
    {
        "type": "text",
        "text": ". SGD ： Adam Adadelta · Adagrad . RMSProp ",
        "page_idx": 80
    },
    {
        "type": "text",
        "text": "1F tf.keras.optimizers.SGD   \n1F tf.keras.optimizers.Adam   \n1F tf.keras.optimizers.Adadelta   \n1F tf.keras.optimizers.Adagrad   \n1F tf.keras.optimizers.RMSProp ",
        "page_idx": 80
    },
    {
        "type": "text",
        "text": "torch.optim.SGD torch.opt.im.Adam torch.optim.Adadelta torch.optim.Adagrad torch.opt.im.RMSProp ",
        "page_idx": 80
    },
    {
        "type": "text",
        "text": "Zeiler et al.,2012. ",
        "page_idx": 80
    },
    {
        "type": "text",
        "text": "Duchi et al.,2011. ",
        "page_idx": 80
    },
    {
        "type": "text",
        "text": "Putting it all together ",
        "text_level": 1,
        "page_idx": 81
    },
    {
        "type": "text",
        "text": "import tensorflowas tf   \nmodel=tf.keras.Sequential([...])   \n# pick your favorite optimizer Can relace with   \noptimizer=tf.keras.optimizer.SGD() optimizer!   \nwhile True:# loop forever #forward pass through the network prediction =model(x) withtf.GradientTape()as tape: # compute the loss loss=compute_loss(y,prediction) #update the weights using the gradient grads=tape.gradient(loss,model.trainable_variables) optimizer.apply_gradients(zip(grads,model.trainable_variables))) ",
        "page_idx": 81
    },
    {
        "type": "text",
        "text": "Neural Networks in Practice: Mini-batches ",
        "text_level": 1,
        "page_idx": 82
    },
    {
        "type": "text",
        "text": "Gradient Descent ",
        "text_level": 1,
        "page_idx": 83
    },
    {
        "type": "text",
        "text": "Algorithm ",
        "text_level": 1,
        "page_idx": 83
    },
    {
        "type": "text",
        "text": "I.Initialize weights randomly ${ \\sim } \\mathcal { N } ( 0 , \\sigma ^ { 2 } )$   \n2.Loop until convergence:   \n3. Compute gradient, $\\textstyle { \\frac { \\partial J ( W ) } { \\partial W } }$   \n4. Update weights, $\\pmb { W }  \\pmb { W } - \\eta \\frac { \\partial J ( \\pmb { W } ) } { \\partial W }$   \n5.Return weights ",
        "page_idx": 83
    },
    {
        "type": "image",
        "img_path": "images/b7a12434e0a29b64d068e528d3e358f28b819baf9966e1afe89bfad19cb83dec.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 83
    },
    {
        "type": "text",
        "text": "Gradient Descent ",
        "text_level": 1,
        "page_idx": 84
    },
    {
        "type": "text",
        "text": "Algorithm ",
        "text_level": 1,
        "page_idx": 84
    },
    {
        "type": "text",
        "text": "I.Initialize weights randomly\\~N(0,σ²)   \n2.Loop until convergence:   \n3. Compute gradient,j(W 1 - 2− 0-   \n4. Update weights, $\\pmb { W }  \\pmb { W } - \\eta \\frac { \\partial J ( \\pmb { W } ) } { \\partial \\pmb { W } }$ -1− 0 0.2 -3→ 1 0.9 0.4   \n5. Return weights M 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 ∗0.8 0.6 0 Can be very computationally intensive to compute! ",
        "page_idx": 84
    },
    {
        "type": "text",
        "text": "Stochastic Gradient Descent ",
        "text_level": 1,
        "page_idx": 85
    },
    {
        "type": "text",
        "text": "Algorithm ",
        "text_level": 1,
        "page_idx": 85
    },
    {
        "type": "text",
        "text": "I.Initialize weights randomly\\~N(0,σ2)   \n2.Loop until convergence:   \n3. Pick single data point i   \n4. Compute gradient, $\\frac { \\partial J _ { i } ( \\pmb { W } ) } { \\partial \\pmb { W } }$   \n5. Update weights, $\\pmb { W } \\gets \\pmb { W } - \\eta \\frac { \\partial J ( \\pmb { W } ) } { \\partial W }$   \n6.Return weights ",
        "page_idx": 85
    },
    {
        "type": "image",
        "img_path": "images/236d3629582a83ed885637ea4365d6c1a146324d07eed3caa82131639f541924.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 85
    },
    {
        "type": "text",
        "text": "Stochastic Gradient Descent ",
        "text_level": 1,
        "page_idx": 86
    },
    {
        "type": "text",
        "text": "Algorithm ",
        "text_level": 1,
        "page_idx": 86
    },
    {
        "type": "text",
        "text": "I. Initialize weights randomly \\~N(0,σ2)   \n2.Loop until convergence:   \n3. Pick single data point i   \n4. Compute gradient,aj(W)   \n5. Update weights, $\\pmb { W } \\gets \\pmb { W } - \\eta \\frac { \\partial J ( \\pmb { W } ) } { \\partial W }$   \n6. Return weights Easy to compute but ",
        "page_idx": 86
    },
    {
        "type": "image",
        "img_path": "images/c02a10cec67363553de1299bc1630e50a93ed3b2d5ebb903244c621fa0b264c3.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 86
    },
    {
        "type": "text",
        "text": "very noisy (stochastic)! ",
        "page_idx": 86
    },
    {
        "type": "text",
        "text": "Stochastic Gradient Descent ",
        "text_level": 1,
        "page_idx": 87
    },
    {
        "type": "text",
        "text": "Algorithm ",
        "text_level": 1,
        "page_idx": 87
    },
    {
        "type": "text",
        "text": "I.Initialize weights randomly ${ \\sim } \\mathcal { N } ( 0 , \\sigma ^ { 2 } )$   \n2.Loop until convergence:   \n3. Pick batch of $B$ data points   \n4. Compute gradient,W) 1R=1W   \n5. Update weights, $\\pmb { W } \\gets \\pmb { W } - \\eta \\frac { \\partial J ( \\pmb { W } ) } { \\partial W }$   \n6.Return weights ",
        "page_idx": 87
    },
    {
        "type": "image",
        "img_path": "images/b7f7d17d512322337adc1192e0a43104df4483ccfec5b569ed0d4e3e19553fe3.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 87
    },
    {
        "type": "text",
        "text": "Stochastic Gradient Descent ",
        "text_level": 1,
        "page_idx": 88
    },
    {
        "type": "text",
        "text": "Algorithm ",
        "text_level": 1,
        "page_idx": 88
    },
    {
        "type": "text",
        "text": "I.Initialize weights randomly ${ \\sim } \\mathcal { N } ( 0 , \\sigma ^ { 2 } )$   \n2.Loop until convergence:   \n3. Pick batch of $B$ data points   \n4. Compute gradient,(W) 1K-1 aw   \n5. Update weights,W ← W-nW   \n6.Return weights ",
        "page_idx": 88
    },
    {
        "type": "image",
        "img_path": "images/bfaf589bb293f3eb2ab79c98660ff1d709077265737de71007138eb608108a10.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 88
    },
    {
        "type": "text",
        "text": "Fast to compute and a much better estimate of the true gradient! ",
        "page_idx": 88
    },
    {
        "type": "text",
        "text": "Mini-batches while training ",
        "text_level": 1,
        "page_idx": 89
    },
    {
        "type": "text",
        "text": "More accurate estimation of gradient Smoother convergence Allows for larger learning rates ",
        "page_idx": 89
    },
    {
        "type": "text",
        "text": "Mini-batches while training ",
        "text_level": 1,
        "page_idx": 90
    },
    {
        "type": "text",
        "text": "More accurate estimation of gradient Smoother convergence Allows for larger learning rates ",
        "page_idx": 90
    },
    {
        "type": "text",
        "text": "Mini-batches lead to fast training! ",
        "text_level": 1,
        "page_idx": 90
    },
    {
        "type": "text",
        "text": "Can parallelize computation $^ +$ achieve significant speed increases on GPU's ",
        "page_idx": 90
    },
    {
        "type": "text",
        "text": "Neural Networks in Practice: Overfitting ",
        "text_level": 1,
        "page_idx": 91
    },
    {
        "type": "text",
        "text": "The Problem of Overfiting ",
        "text_level": 1,
        "page_idx": 92
    },
    {
        "type": "image",
        "img_path": "images/c7eee06949e6514bdead36fea6a6c697a6d4e4e36e39a14ccbdd795e75102d30.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 92
    },
    {
        "type": "text",
        "text": "Model does not have capacity to fully learn the data ",
        "page_idx": 92
    },
    {
        "type": "text",
        "text": "Too complex,extra parameters, doesnot generalizewell ",
        "page_idx": 92
    },
    {
        "type": "text",
        "text": "Regularization ",
        "text_level": 1,
        "page_idx": 93
    },
    {
        "type": "text",
        "text": "What is it? ",
        "page_idx": 93
    },
    {
        "type": "text",
        "text": "echnique thatconstrains ouroptimization problem to discouragecomplex model: ",
        "page_idx": 93
    },
    {
        "type": "text",
        "text": "Regularization ",
        "text_level": 1,
        "page_idx": 94
    },
    {
        "type": "text",
        "text": "What is it? Technique that constrains our optimization problem to discourage complex models ",
        "page_idx": 94
    },
    {
        "type": "text",
        "text": "Why do we need it? ",
        "text_level": 1,
        "page_idx": 94
    },
    {
        "type": "text",
        "text": "Improve generalization of our model on unseen data ",
        "page_idx": 94
    },
    {
        "type": "text",
        "text": "Regularization I: Dropout ",
        "text_level": 1,
        "page_idx": 95
    },
    {
        "type": "text",
        "text": "·During training,randomly set some activations to 0 ",
        "page_idx": 95
    },
    {
        "type": "image",
        "img_path": "images/23c49e8c59c3e7f712c9d8a0d5b074b45fcdfd5a0442e7cfa6b09714888bbf49.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 95
    },
    {
        "type": "text",
        "text": "Regularization I: Dropout ",
        "text_level": 1,
        "page_idx": 96
    },
    {
        "type": "text",
        "text": "· During training,randomly set some activations to 0 ",
        "page_idx": 96
    },
    {
        "type": "text",
        "text": "·Typically'drop'50%of activations in layer . Forces network to not rely on any l node ",
        "page_idx": 96
    },
    {
        "type": "text",
        "text": "tf.keras.layers.Dropout(p0.5) ",
        "page_idx": 96
    },
    {
        "type": "image",
        "img_path": "images/d36271f8a18e0ad1744652663669489fc13485a1d97867635b3229cdd552a30e.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 96
    },
    {
        "type": "text",
        "text": "torch.nn.Dropout(p-0.5) ",
        "page_idx": 96
    },
    {
        "type": "image",
        "img_path": "images/03eb1e836eb622a69d9a3115af5a98229e06177e0225cf7849218d324d305adb.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 96
    },
    {
        "type": "text",
        "text": "Regularization I: Dropout ",
        "text_level": 1,
        "page_idx": 97
    },
    {
        "type": "text",
        "text": "· During training,randomly set some activations to 0 ",
        "page_idx": 97
    },
    {
        "type": "text",
        "text": "·Typically'drop'50%of activations in layer . Forces network to not rely on any l node ",
        "page_idx": 97
    },
    {
        "type": "text",
        "text": "tf.keras.layers.Dropout(p0.5) ",
        "page_idx": 97
    },
    {
        "type": "image",
        "img_path": "images/a6ad014318982ef3af7aacb1ee8d9efa99579e6f790a0cd203801853e4af188a.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 97
    },
    {
        "type": "text",
        "text": "torch.nn.Dropout(p0.5) ",
        "page_idx": 97
    },
    {
        "type": "image",
        "img_path": "images/0a8850ec473745f2d170609f094b931f553bb8343f1cd802d4c5c3997c7a6e82.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 97
    },
    {
        "type": "text",
        "text": "Regularization 2: Early Stopping ",
        "text_level": 1,
        "page_idx": 98
    },
    {
        "type": "text",
        "text": "· Stop training before we have a chance to overfit ",
        "page_idx": 98
    },
    {
        "type": "image",
        "img_path": "images/3142255da170dcd9ec63f65b45d20ee2d6428543a21f7288cc1b99264108ae96.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 98
    },
    {
        "type": "text",
        "text": "Regularization 2: Early Stopping ",
        "text_level": 1,
        "page_idx": 99
    },
    {
        "type": "text",
        "text": "· Stop training before we have a chance to overfit ",
        "page_idx": 99
    },
    {
        "type": "image",
        "img_path": "images/3dcdfecdc07e2f7ae2ab7ea5f1567e4f903d72d844321e5fa2edac715cdf7f7d.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 99
    },
    {
        "type": "image",
        "img_path": "images/fdcd8bf05f33775a3a668c08f39f1ec659e8ae175c568588ef82122d4b73e2d5.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 99
    },
    {
        "type": "text",
        "text": "Regularization 2: Early Stopping ",
        "text_level": 1,
        "page_idx": 100
    },
    {
        "type": "text",
        "text": "· Stop training before we have a chance to overfit ",
        "page_idx": 100
    },
    {
        "type": "image",
        "img_path": "images/c9475231c0ea134ace72c9a256ace4c0e1520dbfab17f2fb7be1d038ed9bef36.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 100
    },
    {
        "type": "image",
        "img_path": "images/29b19c564d7b231498b5c6d782a66162ce0efb50abd3abc759d16e1d8fb13968.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 100
    },
    {
        "type": "text",
        "text": "Regularization 2: Early Stopping ",
        "text_level": 1,
        "page_idx": 101
    },
    {
        "type": "text",
        "text": "· Stop training before we have a chance to overfit ",
        "page_idx": 101
    },
    {
        "type": "image",
        "img_path": "images/2c4ed665f1a79dd552cf76151c446f923d5968ad12363df02c4f214b8bf2af4d.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 101
    },
    {
        "type": "image",
        "img_path": "images/881883d1ae9ab579fb7c856f288ad92a992ad5ff068dc621f9e9f4f2a6e80aa0.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 101
    },
    {
        "type": "text",
        "text": "Regularization 2: Early Stopping ",
        "text_level": 1,
        "page_idx": 102
    },
    {
        "type": "text",
        "text": "· Stop training before we have a chance to overft ",
        "page_idx": 102
    },
    {
        "type": "image",
        "img_path": "images/fb13a65072c580f93b23a62b2cb5e9e6e683905f8abba105f9f40e2c42f88671.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 102
    },
    {
        "type": "image",
        "img_path": "images/913a364fca765aa6b8d588bb2518eed66da971b410b1dc4003e839ebe5c45c26.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 102
    },
    {
        "type": "text",
        "text": "Regularization 2: Early Stopping ",
        "text_level": 1,
        "page_idx": 103
    },
    {
        "type": "text",
        "text": "· Stop training before we have a chance to overft ",
        "page_idx": 103
    },
    {
        "type": "text",
        "text": "6.S1 Legend Loss Testing Training Training Iterations ",
        "page_idx": 103
    },
    {
        "type": "text",
        "text": "Regularization 2: Early Stopping ",
        "text_level": 1,
        "page_idx": 104
    },
    {
        "type": "text",
        "text": "· Stop training before we have a chance to overft ",
        "page_idx": 104
    },
    {
        "type": "image",
        "img_path": "images/c5617456728c99bb31c1ad8c8bcedc4fee92325e7a58ac1610eed5ded0b218a9.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 104
    },
    {
        "type": "text",
        "text": "Regularization 2: Early Stopping ",
        "text_level": 1,
        "page_idx": 105
    },
    {
        "type": "text",
        "text": "· Stop training before we have a chance to overfit ",
        "page_idx": 105
    },
    {
        "type": "image",
        "img_path": "images/f09f86f4f927d6d5f7dd0fe3cb149ababd2c6672311adbfaf342912451e3f29a.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 105
    },
    {
        "type": "text",
        "text": "Core Foundation Review ",
        "text_level": 1,
        "page_idx": 106
    },
    {
        "type": "text",
        "text": "The Perceptron ",
        "text_level": 1,
        "page_idx": 106
    },
    {
        "type": "text",
        "text": "NeuralNetworks ",
        "text_level": 1,
        "page_idx": 106
    },
    {
        "type": "text",
        "text": "Training in Practice ",
        "text_level": 1,
        "page_idx": 106
    },
    {
        "type": "text",
        "text": "·Structural building blocks ·Nonlinearactivation functions ",
        "page_idx": 106
    },
    {
        "type": "text",
        "text": "·Stacking Perceptrons to formneural networks ·Optimization through backpropagation ",
        "page_idx": 106
    },
    {
        "type": "text",
        "text": "· Adaptive learning Batching Regularization ",
        "page_idx": 106
    },
    {
        "type": "image",
        "img_path": "images/2bf9c27f72b1b9f0ecf137313eba152fc5ad654adbda38b548576e4ee34f9c28.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 106
    },
    {
        "type": "image",
        "img_path": "images/5005a2c193640fd00e3c355af617dfa836bf4fe80e82df84e104011c12af224f.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 106
    },
    {
        "type": "image",
        "img_path": "images/4c8844efe7cae4b70c2d297792a35b2589fb1a22f3681ed74bd0ee1a97b25df8.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 106
    },
    {
        "type": "text",
        "text": "MIT Introduction to Deep Learning ",
        "text_level": 1,
        "page_idx": 107
    },
    {
        "type": "text",
        "text": "Labl: Introduction to Deep Learning in Python and Music Generation with RNNs ",
        "page_idx": 107
    },
    {
        "type": "text",
        "text": "Link to download labs: http://introtodeeplearning.com#schedule ",
        "page_idx": 107
    },
    {
        "type": "text",
        "text": "1.Open the lab in Google Colab Startexecuting code blocks and filing in the #TODOs 3．Need help? Come to 32-123! ",
        "page_idx": 107
    }
]