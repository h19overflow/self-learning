![](images/1ce897b749bf69a5c35177b7ad6ad4cf8c782c0a920b22b3fa20153b1bd3dea5.jpg)

# Deep Learning Limitations and New Frontiers

Ava Amini MIT Introduction to Deep Learning January 8,2025

# T-shirts!Tomorrow!

![](images/62e66f0f80ae094a007698930973960c00e5cd5a0b61c3b34d5a7b06521ca721.jpg)

# Class Schedule

IntrotoDeepLearning

![](images/f52b390ef4a505ea6c9ff6738700d3f1ff0c61af25175bc5e6d6d54bb2dd9ca7.jpg)

![](images/eb0efddc8e889660ebf222d3d925dd4dffe2e0e3af4e48f8eb051940b71ed592.jpg)

DeepSequence Modeling

![](images/1e4664f1affbc3cb5fa85aec37a251ec9c8afbf16c563b62c15c4c28db5a1e22.jpg)

Deep Learning in Python;Music Generation

Lecture 1   
Jon.6,2025   
[Slides][Video] coming soon!   
Lecture 2   
Jon.6,2025   
[Slides] Video] coming soonf

Software Lab1 [Code]

![](images/014acaafa8598937f32e5ae7cc8d49f581a52cb67617c884222d8960adbb0ec1.jpg)

![](images/3db72d2cedfb9960d4cca9b6bf551eea00e0054c9c65ba317f29ce47039053a3.jpg)

DeepComputerVision

# Lecture 3

![](images/7ec60a4719de713ddaa4239de13366356e37e9bc0ef09fe3c404c6a1d0b0abb4.jpg)

![](images/fb7b5f3e9a8db52fbdd504b496d82442b6a4c2746a0130e4c347e1f19589f30e.jpg)

Lecture 4   
Jon. 7, 2025   
[Slides] [Video] coming soonf

Deep Generative Modeling

Jon.7,2025 [Slides][Video] coming soon!

FacialDetection Systems

Software Lab 2 [Paper][Code]

![](images/18b6a4dbf04fbe9a3114bb4b6e7dc819a0fe950acccbe45a0e249232d546c2cf.jpg)

DeepReinforcement Learning

NewFrontiers

![](images/6c67917a3f6743517cd1feefc77ffee0c5459e412bb55c7b047d159dc04e491b.jpg)

![](images/456632e06eee469162e72f8c14aa23840b5f709a51192f353c69e6d70951eb4e.jpg)

Fine-Tune an LLM, You Must!

# Lecture 5

Jon. 8,2025 [Slides][Video] coming soon]

Lecture6   
Jon, 8, 2025   
[Slides][video] coming soonf

Software Lab 3 [Code]

![](images/d9e3343bf4a142d81b9df8d1ac1a40a4d34439f99e0610cf0fc41ed7202d0204.jpg)

LargeLanguage Models(1)

?

Large Language Models (1l)

# Lecture 7

# Lecture 8

Jon. 9, 2025 [n][sldes]deogon

Jon. 9, 2025 [info][Slides][Video]coming soon

Final Project

![](images/1808d335e99c03fe53b46c69d7cdf578833fc03612f6fd7d713fde7380d47e12.jpg)

Work on final projects

Alin theWild

![](images/dbc410de27348fbbee2053834e53eeff5f7a4b02289006db674ab4fddc5688a6.jpg)

AlforBiology

· Lab competition: l/10/25 extended! Proposal slides: 1/10/25 ·Proposal pitch: 1/10/25

![](images/fbd8c35c5919c74f6682d5571850e60a95135f6c0fe5256e4144debd5cb88734.jpg)

![](images/9f2c4fc49e4c9371350a36f6b385b48c3898467fe605277d0979145597b4e8ac.jpg)

Project Presentations

Jon.10,2025 [Infe][lides]Vide]ingsoon!

Lecture 10   
Jon.10,2025   
[info][Slides][Video]coming soon!

Pitch your ideas,awards,and celebration!

# Labs and Prizes

![](images/f3ec08e0e09731a055fb7eee582402c383ebd54c6c01a091b2905465b482d80e.jpg)  
Lab l:Music Generation

Lab 2:ComputerVision

![](images/aaeb324344507152fea0e70146dca9b8f4ecb31f3ae65f9cda6fa0ef85e77c3e.jpg)

![](images/e9a376ad455906c6ee7ff94030b497fa41a59e467b9287295fb4a5cca6721b85.jpg)  
Lab3:Large Language Models

Lab submission: I/l0/25 at Il:00am ET-extended deadline! Instructions: bit.ly/6sl9l-syllabus github.com/MITDeepLearning/introtodeeplearning/

# Final Class Project

# Option I: Proposal Presentation

·At least I registered student to be prize eligible   
·Present a novel deep learning research idea orapplication   
· 5 minutes (strict)   
·Presentations on Friday,Jan l0   
·Submit groups by Thu I/9 by I1:59pm ET to beeligible   
·Final slides by Fri I/I0 I:00pm ET   
· Instructions: bit.ly/6s19l-syllabus

· Judged by a panel of judges ·Top winners are awarded:

![](images/35cf7b84851d4d6c53f4d3edd59a23a79d0f811fc641d6521170bc0cce5dcf10.jpg)  
NVIDIA3080 GPU

![](images/33808b4a2f080b719420bf55f5e66e480d9ccc4d81c6db19b5a13b471c4e4859.jpg)  
Smartwatches

![](images/9756ff79b70a8101426cf761e18a19aeae19b6ba1bdb9e93d5203dfca7b82475.jpg)

![](images/065f504af16abb940b116f890a6f9a5f502acc806ec281943c79693e9b0a3eb5.jpg)  
Display Monitors

# Final Class Project

Option 2:Write a l-page review of a deep learning/Al paper

Grade is based on clarity of writingand technical communication of main ideas ·DueFri Jan I0 I:00pm ET · Instructions: bit.ly/6s19l-syllabus

# Program Guest Lectures

![](images/682a8b4a5a47a72b8194c1d280c15100411c3b02d1a66f4a595bba133df7f971.jpg)  
Peter Grabowski Google DeepMind

![](images/459bbf4d6a1ce4dda9678cb105d922e60bbc81a7752f0fcc2881fd56ce00be0c.jpg)  
Maxime Labonne Liquid Al

![](images/4026dc0d59db5b970a974bcd835411732c9d975f68958e6f45cf934c4bf528dd.jpg)  
Douglas Blank Comet ML

![](images/b6cb00afacd3c9582944b4c4f183ceca2e9658f06285cc28b926eeddb654e788.jpg)  
Ava Amini Microsoft

G Google

Liquid

![](images/82609098656b6fe6ede92c52bac446ef33d93deb0e8571597df510598ac54d83.jpg)

# Microsoft Research Forum

Recent research advances in Al, bold new ideas and important discussions with the global research community.

# Register Now

![](images/1be3539c57621c75f2ebf67c004f2169dc4c96407764ed9305dcbe3f2408d7a9.jpg)

Upcoming Episodes February25,2025 June3,2025 October28,2025

Scanthe QRor visitaka.ms/researchforum-mit

So far in Introduction to Deep Learning...

# ‘DeepVoice'Software Can Clone Anyone's Voice With Just3.7 Seconds of Audio

# The Rise of Deep Learning

![](images/8c914f9577316de7096cfe3d1b4bc5e5289471337d3949b76045a26b7450563d.jpg)

# So farin Introductionto Deep Learning...

Data Signals Images Sensors

# Decision

![](images/d7ed45cbe9e615853dfc363be6b927629fd3c801b76cf0fcdeda41bfe90ce031.jpg)

Prediction Detection Action

# Power of Neural Nets

Universal Approximation Theorem

Afeedforward network with a single layer is sufficient to approximate,to an arbitrary precision,any continuous function.

![](images/6634300d58d321d4c869c93e2097b887984a0e4ab9c55d9bed58ea2eda7cec8f.jpg)

# Power of Neural Nets

Universal Approximation Theorem

Afeedforward network with a single layer is suffcient to approximate,to anarbitrary precision,any continuous function.

Caveats: The number of The resulting hidden units may model may not be infeasibly large generalize

# Artificial Intelligence“Hype": Historical Perspective

![](images/f242ceda20db921a070b89745f0cedc5c099239b8172df95a940cfdb4668d26c.jpg)

Limitations

# Rethinking Generalization

Understanding Deep Neural Networks Requires Rethinking Generalization"

![](images/818c012f492b7647d876836a81ab830ea49d23d30231513f0097b20ce95a5b32.jpg)  
dog

![](images/8e68e77783897f51563e3e54847dcf66b1f14494f9e1818892b3531215558981.jpg)  
banana

![](images/2d187c54fdde18fa4d830127bbb17ef8388d1acabd1a12ed42a96794f4bf3d05.jpg)  
dog

![](images/7be3fdaec4a2fa85a0b7ef5eb48cf2eaeb99663caed93563d34ed662de80f565.jpg)  
tree

# Rethinking Generalization

‘Understanding Deep Neural Networks Requires Rethinking Generalization"

![](images/49ed25cd3ac050e00bfc005a980a66efc3208caf9720845f4849af0f36a55dc6.jpg)

# Rethinking Generalization

‘Understanding Deep Neural Networks Requires Rethinking Generalization"

![](images/121b01126b2c11de75a742a33d093ffb6bea7d2475cb86fe4ac1fb13f9363257.jpg)

# Rethinking Generalization

‘Understanding Deep Neural Networks Requires Rethinking Generalization"

![](images/e48e374976ee9313e1c5cb2ad7e0c8d9a871ec0b7bea36469b5855e6fbf20feb.jpg)

# Capacity of Deep Neural Networks

![](images/13db258b1f822ec3414b50f7097360c290c5051fb5a00aea4bab0d61fed4f197.jpg)

# Capacity of Deep Neural Networks

![](images/3b053ee3b59b13eb6913473fcc3fc6ff65b717c79687eda82b85468ca9ad6da2.jpg)

# Capacity of Deep Neural Networks

![](images/a724f52476635ba66f7d23301f356318f8a84aa536817646c6cbfa3ac0c95ac8.jpg)

# Neural Networks as Function Approximators

Neural networks are excellent function approximators

# Neural Networks as Function Approximators

Neural networks are excellent function approximators

6 VS1 MIT

# Neural Networks as Function Approximators

Neural networks are excellent function approximators

![](images/ba13f676a339e9278dabd68e11c09023c348b0594a28c5e9c7e6b6a65cca17fd.jpg)

# Neural Networks as Function Approximators

Neural networks are excellent function approximators

# Neural Networks as Function Approximators

Neural networks are excellent function approximators

MT t/SL

# Neural Networks as Function Approximators

Neural networks are excellent function approximators ... when they have training data

![](images/44a2f68cb81b031bbed9e8cbe5b9bc8768253f5c13d9bdae85efb11f63ec09cb.jpg)

# Deep Learning = Alchemy?

![](images/5e6cbb2f9228027467eba6290593b3fa5249f1a3bcf9cdc4661ba2634f70cdf9.jpg)

![](images/4efb8ee5685d0bffb5ab9cb89f482c7fa18000dc72c2df70bb6c828f5332c6bf.jpg)

# Neural Network Failure Modes,Part I

![](images/c2ef964f878f5be62043b0599d39d1f1b7e47e4255648762c1f7bb3e597c9024.jpg)

金

# What Happens During Training...

![](images/d29ee46b45a7013e92154ba68c79b7a0733f864073d2030d34bbef7693159e07.jpg)

# Neural Network Failure Modes, Part Il

Tesla car was on autopilot prior to fatal crash in California,company says

ThecrashnearMountainView,California,lastweekkilledthedriver.

Dy Mark Osborue March 31, 2018, 1.57 AM • 5 mmn read abeNEWS

![](images/fb48eb975b0b7bdc90ee035369f0cb2bc268cda8f6bcb044c57e59b4a5150906.jpg)

7-10TIMESTHECAR WOULDSWIVELTOWARD THATSAMEEXACTBARRIER DEADLYDISASTER HIGHWAYCRASH TESLA:AUTOPILOTWASONBEFOREMODELXACCIDENTNEWSCOM 1 00:49101:37 中 f X

![](images/c860aa7204cb9831fe2dabff07294829966cb2a9a82c5592896483118fd7d334.jpg)

# Uncertainty in Deep Learning

Safety-critical applications

![](images/144c6b58c041c5e2744e5f7c023039059793119447e02418b04cc0b06b4df350.jpg)

Sparse and/or noisy datasets

![](images/1a061efc560a3bf79a4bc1c9e3accfa421e839687396def8e9efbdb8fb91746d.jpg)

# Neural Network Failure Modes,Part Ill

![](images/5a9c0ed4ef43195c95f91a0d0445f9f4788df75bad24f72a9c72508c362981e3.jpg)

![](images/56ddd996f45d731b008698f10f6e786c8c83d3cb24a828154eb866f50a3ac9b2.jpg)

![](images/3949a70aa90a08587b6d7fc778e066c84e868542c2cf431092b4c05da69bf840.jpg)

Perturbations

Adversarial example Ostrich (98%)

# Adversarial Attacks on Neural Networks

![](images/ee568b4b5a9c9ed2bddca4a9f95d0a3f6b8fe8ef8d3ddc5793ee041c4fc91b51.jpg)

![](images/39ee455b3197eb9a2bb1f149fa65f0085ccd533cb761a0ca18fff3cd6382c1ac.jpg)  
Original image Temple (97%)

![](images/c7d7cd1755ba6efb251af07d0ab0d2ae93f0b2e194de945d96e8ad41693983e8.jpg)  
Adversarial example Ostrich(98%)

Perturbations

# Adversarial Attacks on Neural Networks

# Remember:

We train our networks with gradient descent

$$
W  W - \eta \frac { \partial J ( W , x , y ) } { \partial W }
$$

"How does a small change in weights decrease our loss"

# Adversarial Attacks on Neural Networks

# Remember:

We train our networks with gradient descent

$$
W  W - \eta \frac { \partial J ( W , x , y ) } { \partial W }
$$

"How does a small change in weights decrease our loss"

# Adversarial Attacks on Neural Networks

# Remember:

We train our networks with gradient descent

Fix your image x, and true label y

"How does a small change in weights decrease our loss"

# Adversarial Attacks on Neural Networks

# Adversarial Image:

Modify image to increase error

$$
x  x + \eta \frac { \partial J ( W , x , y ) } { \partial x }
$$

"How does a small change in the input increase our loss"

# Adversarial Attacks on Neural Networks

# Adversarial Image:

Modify image to increase error

$$
x  x + \eta \frac { \partial J ( W , x , y ) } { \partial x }
$$

"How does a small change in the input increase our loss"

# Adversarial Attacks on Neural Networks

# Adversarial Image:

Modify image to increase error

"How does a small change in te input increase our loss"

# Synthesizing Robust Adversarial Examples

![](images/655fcd2c567dad2cd8a6cedaddfff124064cc25b99b016836caeaa84a7a2fd08.jpg)

# Algorithmic Bias

# AI expert calls for end to UK use of 'raciallybiased'algorithms A

# Gender bias in Al: building faireralgorithms

# Millionsofblackpeopleaffectedby racial biasinhealth-carealgorithms

Study reveals rampant racism in decision-making software used by US hospitals − and highlights ways to correct it.

Racial biasinamedical algorithmfavorswhite patientsoversickerblack patients

AI BiasCouldPutWomen's Lives AtRisk-AChallenge For Regulators

Bias in Al: A problem recognizedbut stillunresolved

Amazon,Apple,Google,IBM,and Microsoft worse at transcribing black people's voices than white people's with Al voice recognition,study finds

When It ComestoGorillas,GooglePhotosRemains Blind

Googlefixed'itsracist algorithm byremoving gorillas from its image-labeling tech

# TheWeekin Tech:AlgorithmicBias Is Bad.Uncovering It Is Good.

# The BestAlgorithms Struggleto Recognize BlackFaces Equally

Ugenttstdeppeclcogtesdetysatatfetohttdohie

Artificial Intelligence hasa genderbias problem-justask Siri

# Neural Network Limitations...

· Very data hungry (eg. often millions of examples)   
· Computationally intensive to train and deploy (tractably requires GPUs)   
· Easily fooled by adversarial examples   
· Can be subject to algorithmic bias   
·Poor at representing uncertainty (how do you know what the model knows?)   
·Uninterpretable black boxes,difcult to trust   
·Often require expert knowledge to design,fine tune architectures   
·Dificult to encode structure and prior knowledge during learning   
· Extrapolation: struggle to go beyond the data

# Neural Network Limitations...

Very data hungry (eg. often millions of examples)   
·Computationally intensive to train and deploy (tractably requires GPUs)   
Easily fooled by adversarial examples

· Can be subject to algorithmic bias

· Poor at representing uncertainty (how do you know what the model knows?) ·Uninterpretable blackboxes,dificult totrust

·Often require expert knowledge to design,fine tune architectures ·Dificult to encode structure and prior knowledge during learning . Extrapolation: struggle to go beyond the data

# Neural Network Limitations...

·Very data hungry (eg. often millions of examples)   
·Computationally intensive to train and deploy (tractably requires GPUs)   
·Easily fooled by adversarial examples   
· Can be subject to algorithmic bias   
·Poor at representing uncertainty (how do you know what the model knows?)   
·Uninterpretable black boxes,difficult to trust   
·Often require expert knowledge to design,fine tune architectures

Dificulto encode structure and prior knowledge during learning · Extrapolation: struggle to go beyond the data

# New Frontiers l: Generative Al & Diffusion Models

# The Landscape of Generative Modeling

Lecture 4: VAEsand GANs

![](images/c2ba3ff57f004c8cceaef7f619e6d81c977ec79a8506f6114a510a707a220e9d.jpg)

Limitations

![](images/5df658324043296cc43b5a6667a540a2363bc3dabf393d5b19e08dcd3a314651.jpg)

Mode collapse

![](images/e2bf180b51376fa6d8482e7ecec7c6dc5670e48cb5172786289a98a77dadcbbd.jpg)

Generating OOD

![](images/c9f65ca567726331772687ef7538a67cfe5a5a1328e96a3b202a2939b7e0c913.jpg)

Hard to train

Challenges

Stability

![](images/547c1e08d994c088dc6613116ed6a72d518ea7a7ec8b5b99ac636a550688a607.jpg)

Efficiency

![](images/efa91b9e86ce70cff1f416a816d0a2b80416957c7fc0a5668a0980af9b1b3ab7.jpg)

Quality

![](images/0c2b9254cf2e8f7cbc81bcd28250917e3e1f3a47aaf7357ea34ffc1519337ba6.jpg)

Novelty

# The Landscape of Generative Modeling

Lecture 4: VAEsand GANs

Diffusion Models

Text-to-Image

![](images/1984d55731430863e7d0c4b4864efbd7183c3777a570c058837fcf9fbfacefca.jpg)

![](images/b662852c3788984f8fa7c78c9a63914fa4391a70bcf5d2eddb3172666bb8502f.jpg)

![](images/67a708cd090dd74d494b7dfb51555526560e015323830349c9e4cd0ea83504f5.jpg)

"Two cats doing research"

# Diffusion Models

VAEs/GANs:Generating samples in one-shot directly from lowdimensional latentvariables

Diffusion: Generating samples iteratively by repeatedly refining and removing noise

![](images/bd5175055dc5aa5fab0e02bfc5cbf6fb81c1be86f64c9353e240a28a09344169.jpg)

![](images/47068e4d140f6ba5ed54bf3ac2a742e6a05c43d6e3b67204901017925106feac.jpg)

# The Diffusion Process

Forward noising (data-to-noise)

![](images/704ed34e9e3377a0cb9e76527af282ac8212711a195fd4be0d7eea622f7bdcbd.jpg)

![](images/c1666cc5667653e2d801446fb3b2eb8ee9586f68f95e1d1793bdafa72faaa4a0.jpg)

Reverse denoising (noise-to-data)

# Forward Noising

Step I: Given an image (left),sample a random noise pattern (right)

![](images/f900f10d81aeffbcfdea64468e4eb9abce0e87bc619b78e1c224b63290ebbdc5.jpg)

# Forward Noising

Step 2: Progressively add more and more of the noise to your image

T=0

![](images/e51a09cbeeb935a772f89430554070574b91ba21e14ddf8e0936c2269a079630.jpg)  
100% image 0% noise

![](images/aea55972e5c25fd72cc3d2cfffc982f2f07e8ca7a1bf02d83d1f2b716784188f.jpg)  
T=4   
0% image 100%noise

![](images/cfb820f61d8b87279eb709a23729b5e0b3bd75cd371ad08bbd09019bfcc3f1c8.jpg)  
75% image 25%noise

![](images/97e7555fca4e08e25e53dbd13ddbc1965ea9490e3cf4e230d7f8114d95d28e0e.jpg)  
50% image 50% noise

![](images/2f6413abc10b70e59724abc3814bd392df622309cdb3c3e723dd2c43bf2e745e.jpg)  
25% image 75% noise

# Reverse Denoising

![](images/2735e77703cc6f55f3349a0780923d1ed3201f5876572e430ed0e395ce98621d.jpg)

Goal: Given image at T,can we learn to estimate image at T-I?

![](images/d8e965d799ce5f96822d00978931db7338db07354c72849b3b3a20e87b5ba36a.jpg)

![](images/f3d0e95b40d54bdc9fa914958cadcbcd11081a2e5164bd4861bf4baadc694824.jpg)

![](images/a878a2d3f3854cc64bee603c4c86a192073fed79716775367d5a51e76779fd9c.jpg)

How can we train this network?

# Sampling Brand New Generations

T

![](images/f8d9b98515d9e19000b4eb33ccfd73213d463d899f3670f8c5201948cb7674ee.jpg)

# Sampling Brand New Generations

T

D

# T-I

![](images/2428f82590c24989b6b8a78af34374e410f12df618b2103c1d506751e52ef8cf.jpg)

# Sampling Brand New Generations

# T-I

# T-2

![](images/d078d391104127d946e3c2c8eb9ddf9df247d199870cecc66494ea76746f5b5a.jpg)

![](images/53efa8a098d4c8dbb54bea506c97a435eba428f88c7e61e1d3c0fc10c923e232.jpg)

![](images/e3a035c829d38b53bb1273ecc7666d3a9e3e0665a769090c024aefb91198e96c.jpg)

![](images/71fbda5928ad20710b7bc4d9cb55c1ad210817a09f1717a2141560ea10202b74.jpg)

# Sampling Brand New Generations

# T-2

目 6

T-3

![](images/5eac26b63d1dd319e9c28db88b538b071dae8c1758d52cbe7fe2065a681276c3.jpg)

![](images/ed333501211715fcaa3307a9faac305a93996c026dc406f8ad222afcba2025e9.jpg)

# Sampling Brand New Generations

# T-3

T-4

Z

![](images/363611d2c89dc2a104c9304303cf0de64fbb15d53a76b48df501feedc49a917c.jpg)

![](images/81e591792dbd75a5f6afe7a24955ee856e284575c96bedd80948ce373f2c474f.jpg)

# Sampling Brand New Generations

T-4

T0 (end)

![](images/dd1996c66217e10fcc78d68dd57d905f69927fc724775a7507c5c94024716101.jpg)

![](images/bcb568f964b8817096fc919a802ec16a8fa9a882e3f97cae741620b32e06e374.jpg)![](images/91746a8512b6f0a92056006a0aa9121e7593cdc1057d2fc516a80c4dd9a9e3e4.jpg)

# Sampling Brand New Generations

![](images/70f8a6289eefaa1ca3037e02fe4a1820165998b9b6d4904cabfb67eda33e65eb.jpg)

![](images/6517e72e1f68908b62ad7bb755a3e149ef7a32f1e88a2d485dad2251cbf5ee95.jpg)

![](images/6aa5b4611289d8f2497a9f5eb919f2212752a53a1e1242ca2bbf72d312464372.jpg)

# Generating Images from Natural Language

“A photo of an astronaut riding a horse."

![](images/b4c7ce91c5ad3f6e8a21846c1b69bfb2ee118737d07a574498b1b420ca7fd71b.jpg)

![](images/eb7044d0579b5a90f3bf9f747a02da8ecf06a209e44d15429fe852fe8ae5bb02.jpg)

# Text-to-lmage Generation

“a painting ofa fox sitting ina field at sunrise in the style of Claude Monet"

"an ibis inthe wild,painted in the style of John Audubon”

"close-upofa snow leopard in the snow hunting,rack focus,nature photography"

![](images/27c54dd3a01ea884b3b3cf6c92c4f136b77e0c1f5c7c067a2ccb6492c14e2a42.jpg)

![](images/283d328224f2ea5e760a98fa28d79fd7a3be54400dfc37ed26f69a5d750e410c.jpg)

# Beyond Images: Molecular Design

Chemistry: Generating Molecules in 3D

![](images/1e00d4be939c953e62eefbd7b0e2e498db016d7de8e90835c5ce5ea60594a143.jpg)

![](images/327befe7333a62a8ca6190b99d6b5f77f3a0181f5fa83f5f13758ab8c644ef5a.jpg)

New Frontiers Il: Large Language Models

# Large Language Models (LLMs) and the World

![](images/8f4ca02dc45a13c0f8350389c1c09464f205d3f49e4ec4473d04d64387ac398a.jpg)

# What are LLMs?

# ARTIFICIALINTELLIGENCE

Any technique that enables computerstomimic human behavior

![](images/0f15b6be07b0890aae959b62408939d175d52f132fa0cbd193c4c254f02f9587.jpg)

# DEEP LEARNING

Extract patterns from data using neural networks

![](images/5fe4ccff57649b84bde8f9f3fc84b036ff8d7eb7c011832ffd7a24fa2d3dc96d.jpg)

# LARGE LANGUAGE MODELS

Very,very largeneural networks trained onveryvery largesetsof text

ABCDEF GHIJKL MNOPQR

6.S19l Guest Lectures!

# How do LLMs like GPT work?

Training:

![](images/5caca1b810f02c7e696ece9bf188cc1b5cb0406aa863629ee660d8f6744fcd60.jpg)

Dataset Common Crawl,WebText,etc Split into chunks-"tokens”

Model GPT 175B parameters (GPT3)

Task and Objective:   
Given a sequence of tokens,   
predict the next token.   
Updatemodel parameters given how   
good next-token prediction is.

How does next token prediction work?

# Next Token Prediction

![](images/67803625be41253e774ee8b6dea42b08042d8330852a72e8f2cc683f75048d79.jpg)

# Using LLMs to Generate Text

Training:

![](images/778282dad052aa75b9b82efe336be161ec9c733b5e16868883a5b78339b27e13.jpg)

# Dataset

Common Crawl,WebText,etc Splitintochunks-“tokens"

Model

GPT 175B parameters (GPT3)

Task and Objective:

Given a sequence of tokens, predict the next token.

Update model parameters given how good next-token prediction is.

Deployment:

I'm giving a talk on Al at MIT. Can you outline it?

![](images/333859563ac5e798a7d2501bc3f5ea16ec469dcb5f6e46f74af9a0e59b05e456.jpg)

Introduction   
What isAI?   
HowdoesAl work?   
Howcanweuse Al?

# What capabilities do LLMs have?

Capabilities that are feasible and reliable now:

Knowledge Retrieval

Writing Co-Pilot

Planning Co-Pilot

![](images/be5b60bfc596c0186b7d2b4e8fb480ab740d5315a62b7e49a1f54394a9812acb.jpg)

自ml

![](images/a57ef49f498ab7ad5ed5090ce6503239f79a3d63f80ed0ef74bddf7029032d41.jpg)

LLMs like GPT have shown mastery over natural language.

# Limitations of LLMs

Robustness: How confident?

"Hallucinations": Confidently wrong

Guardrails and Jailbreaks

Logic and Numerics

Cn@uN66rN you translate ths from Spanish to English?

Wang+ arXiv 2023.

![](images/0e28a733a002d481382f8cb416f4ebda113271006a799926cbce7e3a9475bca3.jpg)

![](images/4d85ae6f2cf85b590a5a380b62ebe9083ef2789333c3e1ecf850038b59820080.jpg)

![](images/edb7acda28e4271b50474271974d61eacc23ba9e92106754c623f4166999bd09.jpg)

Key challenges motivated by the high-level thinking process: robustness $^ +$ confidence; long-term planning; logic and discovery

# What can LLMs do? Emergent Abilities with Scale.

An ability is emergent if it is not present in smaller models but is present in larger models.

![](images/475700f99be8369e38ef11d8adf148c85ea9d63a713faa635e3aa51c94fd7d27.jpg)

![](images/73272e6ab09fe12fcf5e40f727672003369ae9a3e5b05fa85b2d6ddc2e19e05a.jpg)

![](images/7396c29ff7d3073d9cfebca9f3953f5b665a88f674c38433f24f98e0b5ee0097.jpg)

# Emergent Abilities:Towards Intelligence

QUESTIONANSWERING ARITHMETIC LANGUAGE UNDERSTANDING 8 billion parameters

![](images/e2856a6469b765a5e7beb870b25084bc0b953df2a513bcf04cae8bb41664a359.jpg)

# Foundation Models Spawn a Powerful Idea

Towards a central reasoning system for general-purpose Al

· Can generative foundation models providea central reasoning system? Design Al to improve and evolve Al itself Generative Al across images, biology language,and more -- power and caution

Relationshipsand connections between artificial and human intelligence