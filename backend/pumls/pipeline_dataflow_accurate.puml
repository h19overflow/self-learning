@startuml Pipeline_Dataflow_Accurate
!theme plain
skinparam backgroundColor #FAFAFA
skinparam defaultFontName Arial
skinparam defaultFontSize 9
skinparam component {
  BackgroundColor #E1F5FE
  BorderColor #0277BD
  FontSize 10
  FontStyle bold
}
skinparam rectangle {
  BackgroundColor #F3E5F5
  BorderColor #7B1FA2
  FontSize 11
  FontStyle bold
}
skinparam database {
  BackgroundColor #E8F5E8
  BorderColor #388E3C
}
skinparam file {
  BackgroundColor #FFF3E0
  BorderColor #F57C00
}
skinparam note {
  BackgroundColor #FFFDE7
  BorderColor #FBC02D
  FontSize 8
}
skinparam package {
  BackgroundColor #F5F5F5
  BorderColor #757575
  FontStyle bold
}

title **Document Processing Pipeline - Accurate Implementation**\n//Based on Real Codebase Analysis//

' --- Input Sources ---
package "**Input Sources**" {
  folder "PDF Input Directory" as PDFInput {
    file "document1.pdf" as PDF1
    file "document2.pdf" as PDF2
    file "..." as PDFMore
  }
  
  file "playlist_sources.json" as PlaylistSources {
    note bottom
      JSON Configuration:
      - YouTube playlist URLs
      - Video metadata
      - Channel information
    end note
  }
  
  component "PipelineConfiguration" as Config {
    note bottom
      Settings:
      - pdf_input_directory
      - output_directory
      - chunk_size & overlap
      - enable_vlm_enhancement
      - enable_video_transcription
      - enable_rag_ingestion
    end note
  }
}

' --- Output Storage ---
package "**Storage Systems**" {
  database "Output Directory" as OutputDir {
    folder "markdown_files/" as MarkdownFiles
    folder "enhanced_files/" as EnhancedFiles
    folder "video_transcripts/" as VideoTranscripts
  }
  
  file "semantic_chunks.json" as ChunksFile {
    note bottom
      Generated by SemanticChunker:
      - Chunk content
      - Source references
      - Metadata mappings
      - Quality scores
    end note
  }
  
  database "ChromaDB Storage" as ChromaDB {
    component "Collections" as Collections
    component "Vector Embeddings" as Embeddings
    component "Metadata Index" as MetadataIndex
  }
}

' --- Stage 1: PDF Processing ---
rectangle "**Stage 1: PDF Processing**" as Stage1 {
  component "process_pdfs_task()" as PDFTask {
    component "PDFToEnrichedMarkdownPipeline" as PDFPipeline
    component "MinerU Processing" as MinerU
    component "File Validation" as FileValidation
    component "Output Cleanup" as OutputCleanup
  }
  
  note right of PDFTask
    **Actual Implementation:**
    
    **Task Configuration:**
    - Retries: 3
    - Retry delay: 30 seconds
    - Error handling: configurable
    
    **Processing Steps:**
    1. Input validation & cleanup
    2. PDFToEnrichedMarkdownPipeline.process()
    3. MinerU engine execution
    4. Markdown file generation
    5. Intermediate file cleanup
    
    **Outputs:**
    - Individual .md files per PDF
    - Processing status & metadata
    - Validation & cleanup results
  end note
}

' --- Stage 1.5: Video Transcription ---
rectangle "**Stage 1.5: Video Transcription**" as Stage1_5 {
  component "video_transcription_task()" as VideoTask {
    component "VideoTranscriptionManager" as VideoManager
    component "Playlist Processing" as PlaylistProc
    component "Transcript Formatting" as TranscriptFormat
    component "Markdown Generation" as VideoMarkdown
  }
  
  note right of VideoTask
    **Actual Implementation:**
    
    **Task Configuration:**
    - Retries: 2
    - Retry delay: 15 seconds
    - Optional based on config
    
    **Processing Flow:**
    1. Load playlist_sources.json
    2. VideoTranscriptionManager.extract_transcripts()
    3. Rich markdown generation with metadata
    4. Structured paragraph formatting
    5. Save to video_transcripts.json
    
    **Output Format:**
    - {video_id}.md files
    - Consolidated transcripts JSON
    - Structured metadata headers
  end note
}

' --- Stage 2: VLM Enhancement ---
rectangle "**Stage 2: VLM Enhancement**" as Stage2 {
  component "vlm_enhancement_task()" as VLMTask {
    component "VLMPipeline" as VLMPipeline
    component "Image Extraction" as ImageExtract
    component "Gemini Integration" as GeminiAPI
    component "Markdown Enrichment" as MarkdownEnrich
  }
  
  note right of VLMTask
    **Actual Implementation:**
    
    **Task Configuration:**
    - Retries: 2
    - Retry delay: 45 seconds
    - Optional: config.enable_vlm_enhancement
    
    **VLM Pipeline Steps:**
    1. Directory validation & cleanup
    2. VLMPipeline.process_directory()
    3. Image reference extraction
    4. Gemini 2.0 Flash API calls
    5. Description integration
    
    **Configuration:**
    - gemini_model: "gemini-2.0-flash-exp"
    - max_concurrent_requests: configurable
    - backup_original_files: optional
  end note
}

' --- Stage 3: Semantic Chunking ---
rectangle "**Stage 3: Semantic Chunking**" as Stage3 {
  component "semantic_chunking_task()" as ChunkTask {
    component "SemanticChunker" as Chunker
    component "LangChain Integration" as LangChain
    component "Nomic Embeddings" as NomicEmbed
    component "File Processing" as FileProc
  }
  
  note right of ChunkTask
    **Actual Implementation:**
    
    **Task Configuration:**
    - Retries: 2
    - Retry delay: 15 seconds
    - Uses LangChain SemanticChunker
    
    **Chunking Process:**
    1. Output file cleanup (if exists)
    2. SemanticChunker initialization
    3. process_output_directory()
    4. Nomic embeddings (nomic-ai/nomic-embed-text-v1.5)
    5. Save to semantic_chunks.json
    
    **Configuration:**
    - chunk_size: from config
    - overlap: from config
    - Fallback: BAAI/bge-large-en-v1.5
  end note
}

' --- Stage 4: ChromaDB Ingestion ---
rectangle "**Stage 4: ChromaDB RAG Ingestion**" as Stage4 {
  component "chromadb_rag_ingestion_task()" as ChromaTask {
    component "ChromaDBManager" as ChromaManager
    component "ChromaConfig Setup" as ChromaConfig
    component "Batch Processing" as BatchProc
    component "Collection Management" as CollectionMgmt
  }
  
  note right of ChromaTask
    **Actual Implementation:**
    
    **Task Configuration:**
    - Retries: 2
    - Retry delay: 20 seconds
    - Optional: config.enable_rag_ingestion
    
    **Ingestion Process:**
    1. ChromaDB configuration setup
    2. ChromaDBManager initialization
    3. ingest_chunks_from_file()
    4. Collection statistics gathering
    5. Resource cleanup
    
    **ChromaDB Settings:**
    - batch_size: 200
    - max_concurrent_batches: 4
    - embedding_device: configurable
  end note
}

' --- Main Orchestration ---
rectangle "**Main Pipeline Orchestration**" as MainOrch {
  component "document_processing_pipeline()" as MainPipeline {
    component "Validation Phase" as ValidationPhase
    component "Parallel Execution" as ParallelExec
    component "Sequential Processing" as SequentialProc
    component "Results Compilation" as ResultsComp
  }
  
  note bottom of MainPipeline
    **Prefect Flow Implementation:**
    
    **Flow Configuration:**
    - ConcurrentTaskRunner
    - Comprehensive logging
    - Error handling & recovery
    
    **Execution Order:**
    1. Input validation
    2. PDF Processing (Stage 1)
    3. Video Transcription (Stage 1.5) [parallel]
    4. VLM Enhancement (Stage 2) [sequential]
    5. Semantic Chunking (Stage 3) [sequential]
    6. ChromaDB Ingestion (Stage 4) [sequential]
    
    **Result Compilation:**
    - Combined statistics
    - Processing duration
    - File counts & metrics
  end note
}

' --- Actual Data Flow (Based on Real Code) ---

' Input Processing
PDFInput --> FileValidation : PDF Files
PlaylistSources --> PlaylistProc : Playlist Config
Config --> PDFTask : Pipeline Configuration
Config --> VideoTask : Pipeline Configuration
Config --> VLMTask : Pipeline Configuration
Config --> ChunkTask : Pipeline Configuration
Config --> ChromaTask : Pipeline Configuration

' Stage 1: PDF Processing Flow
FileValidation --> OutputCleanup : Validated Files
OutputCleanup --> PDFPipeline : Clean Environment
PDFPipeline --> MinerU : PDF Processing
MinerU --> MarkdownFiles : Generated .md Files

' Stage 1.5: Video Processing Flow (Parallel)
PlaylistProc --> VideoManager : Video URLs
VideoManager --> TranscriptFormat : Raw Transcripts
TranscriptFormat --> VideoMarkdown : Formatted Content
VideoMarkdown --> VideoTranscripts : {video_id}.md Files

' Stage 2: VLM Enhancement Flow (Sequential)
MarkdownFiles --> ImageExtract : All .md Files
VideoTranscripts --> ImageExtract : Video .md Files
ImageExtract --> GeminiAPI : Image References
GeminiAPI --> MarkdownEnrich : AI Descriptions
MarkdownEnrich --> EnhancedFiles : Enhanced .md Files

' Stage 3: Semantic Chunking Flow (Sequential)
EnhancedFiles --> FileProc : Enhanced Content
FileProc --> NomicEmbed : Text Processing
NomicEmbed --> LangChain : Embeddings
LangChain --> Chunker : Semantic Segmentation
Chunker --> ChunksFile : semantic_chunks.json

' Stage 4: ChromaDB Ingestion Flow (Sequential)
ChunksFile --> ChromaConfig : Chunk Data
ChromaConfig --> BatchProc : Configuration
BatchProc --> CollectionMgmt : Batch Processing
CollectionMgmt --> ChromaDB : Vector Storage

' Results to Main Pipeline
PDFTask --> ResultsComp : PDF Results
VideoTask --> ResultsComp : Video Results
VLMTask --> ResultsComp : VLM Results
ChunkTask --> ResultsComp : Chunk Results
ChromaTask --> ResultsComp : RAG Results
ResultsComp --> MainPipeline : Final Results

' Component Dependencies (Real Implementation)
PDFPipeline ..> MinerU : "uses MinerU engine"
VideoManager ..> PlaylistProc : "processes playlists"
VLMPipeline ..> GeminiAPI : "calls Gemini 2.0 Flash"
Chunker ..> LangChain : "uses LangChain SemanticChunker"
ChromaManager ..> BatchProc : "handles batch ingestion"

' Actual File Outputs
PDFTask --> OutputDir : ".md files per PDF"
VideoTask --> OutputDir : "{video_id}.md files"
VLMTask --> OutputDir : "enhanced .md files"
ChunkTask --> ChunksFile : "semantic_chunks.json"
ChromaTask --> ChromaDB : "vector embeddings"

' Error Handling & Monitoring (Real Implementation)
ValidationPhase --> ParallelExec : "validation_results"
ParallelExec --> SequentialProc : "pdf_results, video_results"
SequentialProc --> ResultsComp : "vlm_results, chunk_results, rag_results"

@enduml